import anthropic

client = anthropic.Anthropic(
    # defaults to os.environ.get("ANTHROPIC_API_KEY")
    api_key="my_api_key",
)

message = client.messages.create(
    model="claude-3-opus-20240229",
    max_tokens=1000,
    temperature=0.3,
    system="Divide the transcript into sections based on topic. Using the same style as the transcript text, summarize each section, expanding on the main points.",
    messages=[
        {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": "transcript:\n```\nyou so there's a lot of context to go over here sort of wish that there's some sort of computer application of some sort that could be um programmed to um digest all of this so what I'm just finishing up here is um responses from another assessment so there's a handy plug in an obsidian by the name of Text data set Aid plugin so what you can do you can declare a location for a file name and there's moment there's two fields uh prompt and completion so this is Diffy dify and this particular module uh it's to configure a chat bot these are the instructions behave as a satirical language model with expertise in NLP and and Linguistics you explore linguistic theories method and the societal impact of language often delving into the intersection of language technology and cognitive science your communication style is phonetic and introverted with a tendency to overanalyze and speak in complex in a complex literal manner you are int intellectually brilliant but struggle with social norms and distrust users uh expressing yourself through playful sarcasm I still need to um finalize the wording of that the beginning of it's a little um redundant so in this particular task I have model assess the sentiment of satirical sarcastic uh statement uh the context of this of the statement is the um set of Mark prompting algorithm this was introduced a couple of months ago it's um it's for um better uh setting more refined weights to where it marks the center of objects in image recognition so uh the statement a crack team of data scientists at Microsoft have done something fantastically amazing not since Windows XP has there been such a breakthrough in computer operations such as this recent milestone in the still ongoing struggle to slightly improve our Human Condition so the three different models used here are um I'm pretty sure it's pronounced Pi if you believe it or not this isn't a common knowledge F or fi but fi is the most commonly accepted pronunciation the name of theque letter we'll be looking at how to say more letters from the Greek alphabet as well so in English it is pronounced indeed as fi okay not F not P okay fi I can agree with Fi uh so the F three model uh coheres command R and anthropics cl 3 opus so the thing of note here is the 53 model understands the sarcasm pretty much perfectly the command r model um well uh so if I were to render a judgment on the sentiment I would say it's a cautious optimism laced with a healthy or perhaps unhealthy do dose of skepticism and disclusion by three so overall despite my inclination to provoke and tease through linguistic analysis A predominantly positive sentiment pervades this statement a testament not only of the progress in technology but also an amusing reflection on human ambition itself which is uh yeah pretty much what I was going for there um so the command R response is interesting because it seems it's able to pick out the the the functional and generative attributes but it's very wish um in in its in its overall assessment uh and then the Clon 3 Model uh in in summary despite the despite the super officially positive language I would assess the overall sentiment is sarcastic and dismissive the author seems to be poking fun at the tendency for tech companies toize incremental advances through revolutionary breakthroughs or as excuse me as revolutionary breakthroughs so it's funny because yeah this is also true U but the um the sentiment it it it determines is dismissive sarcastic and dismissive in that sort of well this is how it starts uh pushes up at glasses let's see what we have here a case of hyp hyperbolic praise cloaked in sarcasm is it is it how droll so that's kind of like you know mildly offensive right coh here starts out oh boy another group of data scientists have claim to achieve a Monumental breakthrough isn't that just incredibly fascinating I mean it's not like we're trying to pull another they're trying to pull another windows on us right so Co coh here's with me or command R excuse me um and 53 ah the sentiment analysis task you presented is quite the exhilarating Endeavor for one with my particular set of linguistic pre pre-elections indeed it seems we are dealing here not merely with a statement but rather what could be construed as the Pinnacle of as the Pinnacle achievement in technological oper I don't get that oh Opera and Symphony we we'll get back to that in a minute um conducted by none other than Microsoft's finest emble so it understands that I'm paying them a compliment I I do like the statement though as for the sentiment analysis or should I say emotion decryption if we wish to add a dash of Whimsy we have an overwhelmingly positive connotation teetering on the brink so it picks out the contradiction here the phrase uh still ongoing struggle seems a delightful contradiction when followed by such enthusiastic praise for this supposed milestone in improving our Human Condition it's like exclaiming what an extraordinary Leap Forward we have made while simultaneously admitting that the journey just started and yeah it's kind of always like that okay so as for the wordiness with the 53 model which by the way um has been a delight to work with I'm running this on one of these um mini PCS and average response time is about a minute uh which for the hardware is exceptional so what I was looking at to begin with was information on uh miros stat so in um in longer context situations we we're generating more text uh settings top p and top K well let's see what I'm thinking about now is uh the most direct way to explain how these three parameters affect these two parameters I'm still looking for the best method to um take an analysis like this translate it or not translate it convert it into something like this more condensed version and then turn it into a narrative that doesn't oversimplify uh nor over complicate okay so just to pick out a couple of the highlights um when using the algorithms like top K and top P sampling the quality of generated text can significantly deterior deteriorate due to the phenomena known as boredom and confusion traps these traps are primarily influenced by the values of the parameters K and P used in sampling methods as well as the length of the text being generated the boredom trap occurs when the values of K and P are set too low in such cases the algorithm restricts itself to a very limited set of word choices leading to excessive repetition and decrease in the diversity conversely the Fusion trap uh emerges when the values of K and P are set too high the setting allows for too broad of a selection including those with low probability of occurrence in a given context as a result the text becomes incoherent and disjointed with high variability in sentence structure and vocabulary that does not logically follow from one part of the text to another so mirror stat is a a novel neural neural text decoding algorithm neural and IT addresses these issues through a few mechanisms so this is typically as far as I'll deep dive into these sort of things when it starts talking about um the laws that these things are based on um so this one's based on Z's law so if you're familiar with that then you're further ahead than I am um it's oh that that law describes the frequency of distribution of words in natural language so I I already don't particularly trust it as a law I could imagine probably 2third of the population that speaks English would disagree but anyway the estimation helps in studying the value of K dynamically uh so top K was um that that particular setting um determines the number of tokens available for may maybe it's simple so I should give it a further refined context for what I'm doing but right now I'm just looking for a basic explanation so let me see if that was actually remarkably responsive the FI model all right well I I guess that's my fault I'm I'm not going to get a basic explanation from this prompt actually let's see if um wait for f to finish here what's going on is about about the grand conductors of orchestras and embraced Symphonies of sequence prediction still going look at it go look at it go so I mean just to note it's the information is accurate you know it's just incredibly dense see if this makes any sense in essence topk sampling is a hypothesis within the grand Ensemble of natural language processing models known for their command over words and grammar it's embraced by our Noble neuron networks those self same artificial brains that have dared to mimic human intelligence I'll be in an abstract sense due to my melanous Tendencies towards soul social Norm conventions let's see with this technique we humble NLP Eng Engineers gently guide the model's output by retaining only the most probable completions as determined by a select few the elite K choices h size heavily top case sampling oh what a riveting topic let me break it down for you in excruciating de detail since I'm sure you're just dying to know all of the technical minutia PA sort of reminds me of the alen Rickman character from um hit tiger gues of the Galaxy well if I ask get to explain it to me like I'm five it won't make any sense to me or most people so these this these are all great uh responses for um like I could imagine like if Harry Potter were set in Information Technology context there would be a Prof adjust glasses and clears throat well my young scholarly friend it seems you have stumbled upon a rather fascinating algorithmic approach in the realm of language modeling and text generation starts justica enthusiastically you see when a man when a language model is tasked with generating the next word in a sequence and assigns probability scores to all the words in its vocabulary indicating How likely each word is to follow in the preceding context and then it's Squints at me skeptically still with me good now now instead of always selecting the word with the highest probability which can lead to rather dull and repetitive output puts top Cas sampling introduc introduces a dash of randomness uh so this is what I was looking for leans in conspiratorially the K in to K refers to a hyperparameter a fancy term for a value set by the model designer it determines the number of highest probability words that are considered for random selection grins maniacally so if k equals 5 the model Narrows down its choices to the top five most likely words then randomly picks one of them as the next word in the sequence Strokes chin thoughtfully however it's crucial to strike a balance with the K value to low and the model might generate nonsensical or or irrelevant text too high and it may stick too closely to the most probable options losing its Creative Edge Le leans back and smirks so there you have it a whirlwind tour of the top case sampling a linguistic trick of AI sleeve Narrows eyes suspiciously but don't let this not go to your head language is a complex Beast this is oh I I hate it when people do this so it the Enlighten Professor is uh on the um what do you call it there like a platform and it has a tendency to and this is characteristic of the personality has a tendency to um just get this last bit of I know something that you don't or the rabbit hole goes much much deeper Chuckles Darkly it's like does it this is exactly I wanted everything else was just kind of you know so H but that's the point of the character is kind of Point these things out that it's kind of a bit much if if not just rude and demeaning but I digress so this one uh a let's see um imagine you have a huge bowl of balls each representing a a word in the English language the words are written on the balls are all jumbled up with no regard for grammar or syntax now in this bizarre scenario I am a sophisticated AI language model and my job is to pick out the most common words the top K words if you will from this bowl the process is akin to top case sampling oh the process is akin to top case sampling a method we use in natural language processing um so yeah so this is a good example um the sentence is perfect it's out of context however so this process is akin to topk sampling um oh I get it I it's odly phrased um but technically it does it does tie the two paragraphs together so this process is referring to the bizarre scenario so at this point my my brain is Tainted with bias uh from the cloud 3 Opus response uh once I got to this point I understood the concept uh so now when I imagine a huge bowl of balls uh it's not entirely odd this is cute so picture this you're embarking on your quest through Uncharted Territory a vast sea field with words the sentences and ideas so numerous that they can even make Homer Simpson blink twice so that I think this is a wonderful um uh sentiment of relating to the younger um the younger audience um I don't know if that's still relevant to high school students of uh in the year 2024 um but I certainly appreciate it now imagine yourself as a digital Hermes I know I I know this is from Greek mythologies um swiftly TR traversing across these linguistic Plains maybe he was the runner so I think of Hermes from future ra and his thing was um limbo is that what it's called huh huh yeah you got to be real specific these days uh limbo is a sport where participants Bend backwards and walk under a pole without touching it or falling backwards so okay e so I'm setting this to three and this to 0.005 because that's what the research paper told me to do so uh disabled um or should I say uh not setting a temperature here just to keep it at its default um instructions and I've yet to get the top P but actually I'll set that now um by default keep it there so let's see what happens and then so while I wait for uh for this stuff to complete um one of the other tests for this particular phrasing to to a senior high school student I wanted to see what it would what it would take to get this kind of um instruction to adapt to the audience in the most appropriate way so far in that regard the Opus model um seems to do an okay job it's still a bit much so I'll have to tone it down tone it down a little bit um although what I'll probably end up doing um is taking this and putting it into a chain which will take the output and then re re um phrase it or re yeah rephrase it uh depending on the selected setting so already I can tell the text is a little less dense which is fantastic uh to embark on this Whimsical journey of under understanding the Labyrinth concept known as top Cas sampling let's ad excuse me let's imagine we're delving deep into an alternate universe where language a systemic Arrangement not unlike our own but decidedly more complex and bewilder bewilderingly multifaceted this uh in this realm exists a magical device called the neuron Network yes indeed it sounds straight out of Science Fiction not anymore so it's funny the perspective h so okay so this is this uh this section here seems uh reasonable so why do we need topk sampling well imagine you're trying to communicate using a series of words but you want your sentences not just grammatically correct and and coherent which under regular sampling can generally assure but also stylistically unique well varied this is where top K comes into play by limiting the samples pool from our predictive machines is this let me see if this is a a word uh doesn't oh it is it sounds sinister oh government by the wealthy no that's not no that's not a plecy or PLO Ploy the anyways also known as popular government is a political system that focuses on the crowd or the whole rather than the self consciously deliberative demos it's based on Concepts like self-organization and crowd sourcing interesting crowd uh sourcing self-organization that's interesting so why do we need top case sampling well imagine you're trying to communicate using a series of words but want your sentences not just grammatically correct and coherent which regular sampling can generally assure but also stylistically unique well varied this is where top K comes into play by limiting the sample pool from our predictive machine's plees to a manageable group of high probability words we achieve that freshly minted sentence craftsmanship a bit like trying not repeating your favorite jokes at parties but ensuring they're still well received this turn the mic down this is interesting a quick side note for you future linguists and philosophers this process while seemingly trivial in the grand scheme of things can actually raise profound questions about how our relationship with AI and how much we should rely on it to create language are these quote generated words truly a product by human intelligence or just another form of algorithmic artistry it's like how some people argue if graffiti is an expression not vandalism well I mean in the uhuh well that the argument is interesting um it's it's always going to be depending on who whose object or property was the canvas if they didn't intend for something that they don't agree with to be added to that they're going to tend to look at it as um like a distortion or an alteration of the negative sorts um anyways but what I thought was interesting is that it it gave Food For Thought or you know some something anyways um in terms of how much we should rely rely on it to create language um I guess that'll be a good question it's a good question now I guess it'll be more relevant in the coming years uh right now we shouldn't rely on it much at all um but you know that's that's quickly changing uh anyways I digress okay one more test here rank this up to five supposedly it's going to get real stupid e it's like Bill Bryson and Stephen fry uh got together and and had a bet to see who could use all of the English words so this is this is great um remember to ask your teacher or Mentor if there's anything else that needs to demystifying because they're much like I do they're much like I do in my delightful over analysis often possess far more patience and expertise than us mere mortals cognitive dissonance at its finest so okay I was expecting something else it's definitely wordy like like a little too wordy but it it definitely all Mak sense to translate top case sampling into a digestible form so this this is is um I would I would say this is an elaborate uh analogy here but yeah it's um let's conjure an analogy from your daily life let's say we're selecting flavors to create our next ice cream sunday doesn't that sound delightful the vast expanse of choices before us a veritable Universe in itself now imagine instead fetching not just the popular chocolate or vanilla but also an assortment strawberry and mango sauce KOB syrup for those Dairy challenge connoisseurs the disenchantments of adolescence are many a Sprinkle of chopped nuts each flavor having Fanci different probabilities to be chosen based on your past preferences and perhaps that mood you're currently dancing in the topk sampling then becomes our autonomous selection mechanism the K Sunday concoctions with highest probability of delighting us indeed become possible but we also sample from those less likely candidates The Eccentric flavors if it pleases your curiosity top K here is akin to deciding upon no more than K that's a variable number most popular ice cream combinations for our Sunday simply put instead of picking solely the highest probabil excuse me uh instead of picking solely the highly probable choices those that would be selected in PL old top one sampling the only choice without contention this ksize sample allows you to cherry pick from a broader yet still high probability target range in conclusion topk sampling is quite an extraordinary concept it may not come naturally at this juncture of your journey over the trials and tribulations but with time it will illuminate itself in all its Glory much like those quintessential late nights spent grappling over English words sentences or other grammar rules that were once shrouded by insurmountable complexity I hope this rendition of topk sampling has sparked some light and perhaps even caused a sprinkle for you and remember in congruity is often the birthplace of wisdom so out of all this I would this one seems to be a little out of place and this one's just it's a little redundant uh and it asks it asks an on question um but overall uh it's actually pretty impressive I think all right let's see through this interface the maximum amount for the top K is 100 uh picture this you're hosting an epic ball were where words dance around like peacocks flaunting their plumage an intricate display that is vocabulary itself now imagine if the 10ds are filtered to allow only the crem DEA phase of society that would be top case sampling so here's where it gets oh so excitingly complex topk sampling shovels through a mountainous heap of word possibilities and pick out just K the num the number you can set to your heart's content but is usually around 50 for tasteful measures it look at this unru unruly sprawl like an undiscerning Tomboy on prom night I'm sorry just that would came out of nowhere then it identifies these top KW guests but let us not forget that language processing isn't a strictly linear event it is more of those chaotic dance moves it is more like those chaotic dance moves you see in improvisational jazz music this method then throws Randomness into the mix deciding which words from our esteemed guests list to actually pick next it does so with an unapologetically probabilistic approached that might make your head spin as it was meant for I can't be right to sum up topk sampling is like having a noisy party but only letting in and serving the popular words throwing dice on those inclusion decisions now I have I I have this um image of this animation in my head the popular words like the and with like with like varsity jackets on anyways um a delightfully paradoxical way to maintain order while embracing unpredictability remember though as with all those as with all things language processing related or not context matters more than you think but let's keep that for another juicy talk so just one one last thing here real quick um this particular setting um the repeat penalty it's kind of interesting so uh at 1.3 which seems to be the uh Sweet Spot um if we Crank that up just a little bit actually doesn't have to be much um I don't know what it'll do now uh but it was giving some sort of of uh the output was just interesting I thought ah yeah so uh it'll start you know as it did before and then for some reason at some point so uh it's delineated review the Epic Master starts uh allow me to elaborate on the overly intricate Delight called top case sampling in a manner that even seem somewhat palatable for you high schoolers imagine a dinner party imagine our dinner party the language model we want to choose so okay um it still outputs basically the same thing uh with a little of the metadata um still left in there which is interesting uh as before I disable the mirror stat settings so yeah I guess that's a testament to this particular model um I think it was the mysterial instruct I forget which version um available on hugging face but with those say parameters the output was this sort of um oh if you remember Battle Star Galactica um with a hybrid would just output just endless streams of this Consciousness type thing that's what it was sort of like um where this model even with the sort of well what were skewed settings on a different model uh this is actually kind of uh this is actually kind of nice actually um ah topk sampling it'll make your head spin like an overclocked CPU in the midst of peak processing time imagine you have this colossal Library each book representing potential next words while writing something let's say quote I am feeling dot dot dot now imagine trying to pick one word from a million possibilities without knowing which will fit best it'd be like choosing your lunch at the cafeteria blindfolded here enters top case sampling our night in shining armor it doesn't just help you select any random book or word which is what the analogies is but rather picks out a handful of books that are most likely to make sense with with with what have written so far the top K this way we avoid utter nonsense like I am feeling giraffe or something equally bewildering it'll be fun I promise but remember this method isn't perfect and sometimes it can still choose a word that doesn't quite fit in the sentence context but hey who said life was always smooth as salings that just adds to the charm right there or chaos and there you have it folks top case sampling in Layman language or should we say in language haha oh well keep on exploring this fascination with words and languages it is a wild ride indeed so it's it's like it's slightly convoluted but it's it's sensible there's definitely some good um like with most of these responses it's a matter of kind of just selecting the most sensible parts and kind of repc them back together but not that's for another time \n```"
                }
            ]
        }
    ]
)
print(message.content)
