var search_data = {"index":{"searchIndex":["api","accumulatefilteredsegmentstask","agent","cartridge","cursor","displayresultstask","fileloadertask","fileobject","filtersegmentstask","flowbots","cli","exceptionagent","exceptionhandler","fileloader","filenotfounderror","grammarprocessor","nlpprocessor","task","tasknotfounderror","textprocessingworkflow","textprocessor","textsegmentprocessor","texttaggerprocessor","texttokenizeprocessor","topicmodelprocessor","topicmodeltrainerworkflow","topicmodeltrainerworkflowtest","workflows","flowiseapiclient","jongleur","workertask","lemma","llmanalysistask","loadtextfilestask","logging","markdownyaml","document0","yamlfrontmatter0","yamlfrontmatter1","markdownyamlparser","monadicerror","nlpanalysistask","object","preprocesstextfiletask","redisconnection","segment","sublayer","actions","runtestcommandaction","speechtotextaction","texttospeechaction","writefileaction","tty","markdown","converter","promptx","task","textsegmenttask","texttaggertask","texttokenizetask","tokenizesegmentstask","topic","topicmodelingtask","traintopicmodeltask","ui","word","workflowagent","workfloworchestrator","_nt_document()","_nt_markdown_content()","_nt_newline()","_nt_yaml_front_matter()","add_agent()","add_lemma()","add_lemmas()","add_lemmas_to_textfile()","add_segment()","add_segments()","add_topics()","add_word()","add_words()","add_words_to_segment()","after_delete()","after_save()","analyze_transitivity()","call()","call()","call()","call()","classify_file()","clean_segments()","clean_segments_for_modeling()","clean_segments_for_modeling()","cleanup()","complete()","completed()","configure_logger_for()","convert_p()","create_doc()","create_new_model()","create_or_fetch_file_object()","create_with_timestamp()","current_batch()","custom_workflow()","define_workflow()","display_filtered_segments()","display_results()","display_workflows()","duration()","edit_api_settings()","edit_general_settings()","edit_workflow_settings()","ensure_model_exists()","evaluate()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","exit_on_failure?()","extract_main_topics()","extract_markdown_content()","extract_metadata()","extract_relevant_files()","extract_text()","extract_text_json()","extract_workflow_description()","extract_yaml_front_matter()","fail()","failed()","fallback_exception_report()","fetch_unprocessed_file_ids()","filter_segment_words()","filter_segment_words()","filter_segments()","find_or_create_by_path()","flush_redis_cache()","format_analysis()","format_exception_report()","format_file_info()","format_nlp_result()","format_output()","generate_analysis_prompt()","generate_exception_prompt()","get_object_attributes()","get_object_bucket()","get_object_by_name()","get_object_collections()","get_object_indexed_attributes()","get_object_references()","get_objects()","get_objects_by_collection()","get_objects_by_query()","get_objects_by_reference()","get_objects_by_regex()","get_workflows()","handle_exception()","handle_response()","identify_speech_acts()","in_progress()","infer_topics()","initialize()","latest()","list_and_select()","load_components()","load_content()","load_engtagger()","load_existing_model()","load_file_structure()","load_grammar()","load_model()","load_or_create_model()","load_state()","load_tasks()","load_workflows()","log_exception()","log_level()","logger()","logger_for()","main()","markdown_content()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","newline1()","newline2()","notify_exception()","open_settings()","parse()","parse_pdf()","pending()","perform_additional_tasks()","pos()","predict()","process()","process()","process()","process()","process()","process()","process_batch()","process_batch()","process_exception()","process_files()","process_single_file()","process_text()","prompt_for_file()","prompt_for_folder()","prompt_for_folder()","readline()","reflect()","retrieve_file_metadata()","retrieve_filtered_words()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_input()","retrieve_memories()","retrieve_nlp_result()","retrieve_segment_texts()","retrieve_segments()","retrieve_word_texts()","retrieve_word_texts()","retrieve_words()","retrieve_words()","root()","run()","run()","run()","run()","run_workflow()","run_workflow()","save_model()","save_state()","segment_array()","segment_string()","select_workflow()","setup_redis()","setup_workflow()","shutdown()","splat_sort()","start()","start_workflow()","stop_running_workflows()","store_fileobject_id()","store_analysis_result()","store_episodic_memory()","store_file_data()","store_preprocessed_data()","store_result()","store_segments()","store_textfile_id()","store_topic_result()","tokenize_array()","tokenize_string()","train_model()","train_topic_model()","train_topic_model()","train_topic_model()","update_file_object()","update_segment_with_nlp_data()","update_semantic_memory()","update_state()","upsert_document()","version()","view_logs()","workflows()","write_markdown_report()","write_markdown_report()","yaml_front_matter()","license","readme"],"longSearchIndex":["api","accumulatefilteredsegmentstask","agent","cartridge","cursor","displayresultstask","fileloadertask","fileobject","filtersegmentstask","flowbots","flowbots::cli","flowbots::exceptionagent","flowbots::exceptionhandler","flowbots::fileloader","flowbots::filenotfounderror","flowbots::grammarprocessor","flowbots::nlpprocessor","flowbots::task","flowbots::tasknotfounderror","flowbots::textprocessingworkflow","flowbots::textprocessor","flowbots::textsegmentprocessor","flowbots::texttaggerprocessor","flowbots::texttokenizeprocessor","flowbots::topicmodelprocessor","flowbots::topicmodeltrainerworkflow","flowbots::topicmodeltrainerworkflowtest","flowbots::workflows","flowiseapiclient","jongleur","jongleur::workertask","lemma","llmanalysistask","loadtextfilestask","logging","markdownyaml","markdownyaml::document0","markdownyaml::yamlfrontmatter0","markdownyaml::yamlfrontmatter1","markdownyamlparser","monadicerror","nlpanalysistask","object","preprocesstextfiletask","redisconnection","segment","sublayer","sublayer::actions","sublayer::actions::runtestcommandaction","sublayer::actions::speechtotextaction","sublayer::actions::texttospeechaction","sublayer::actions::writefileaction","tty","tty::markdown","tty::markdown::converter","tty::promptx","task","textsegmenttask","texttaggertask","texttokenizetask","tokenizesegmentstask","topic","topicmodelingtask","traintopicmodeltask","ui","word","workflowagent","workfloworchestrator","markdownyaml#_nt_document()","markdownyaml#_nt_markdown_content()","markdownyaml#_nt_newline()","markdownyaml#_nt_yaml_front_matter()","workfloworchestrator#add_agent()","fileobject#add_lemma()","fileobject#add_lemmas()","nlpanalysistask#add_lemmas_to_textfile()","fileobject#add_segment()","fileobject#add_segments()","fileobject#add_topics()","segment#add_word()","segment#add_words()","nlpanalysistask#add_words_to_segment()","fileobject#after_delete()","fileobject#after_save()","flowbots::texttaggerprocessor#analyze_transitivity()","sublayer::actions::runtestcommandaction#call()","sublayer::actions::speechtotextaction#call()","sublayer::actions::texttospeechaction#call()","sublayer::actions::writefileaction#call()","flowbots::fileloader#classify_file()","accumulatefilteredsegmentstask#clean_segments()","flowbots::topicmodeltrainerworkflow#clean_segments_for_modeling()","flowbots::topicmodeltrainerworkflowtest#clean_segments_for_modeling()","workfloworchestrator#cleanup()","task#complete()","task::completed()","logging::configure_logger_for()","tty::markdown::converter#convert_p()","flowbots::nlpprocessor#create_doc()","flowbots::topicmodelprocessor#create_new_model()","flowbots::textprocessingworkflow#create_or_fetch_file_object()","task::create_with_timestamp()","fileobject::current_batch()","ui::custom_workflow()","workfloworchestrator#define_workflow()","filtersegmentstask#display_filtered_segments()","displayresultstask#display_results()","flowbots::workflows#display_workflows()","task#duration()","ui::edit_api_settings()","ui::edit_general_settings()","ui::edit_workflow_settings()","flowbots::topicmodelprocessor#ensure_model_exists()","cartridge#evaluate()","accumulatefilteredsegmentstask#execute()","displayresultstask#execute()","fileloadertask#execute()","filtersegmentstask#execute()","flowbots::task#execute()","llmanalysistask#execute()","loadtextfilestask#execute()","nlpanalysistask#execute()","preprocesstextfiletask#execute()","task#execute()","textsegmenttask#execute()","texttaggertask#execute()","texttokenizetask#execute()","tokenizesegmentstask#execute()","topicmodelingtask#execute()","traintopicmodeltask#execute()","flowbots::cli::exit_on_failure?()","flowbots::texttaggerprocessor#extract_main_topics()","flowbots::grammarprocessor#extract_markdown_content()","preprocesstextfiletask#extract_metadata()","flowbots::exceptionagent#extract_relevant_files()","flowbots::fileloader#extract_text()","flowbots::fileloader#extract_text_json()","flowbots::workflows#extract_workflow_description()","flowbots::grammarprocessor#extract_yaml_front_matter()","task#fail()","task::failed()","flowbots::exceptionagent#fallback_exception_report()","flowbots::textprocessingworkflow#fetch_unprocessed_file_ids()","filtersegmentstask#filter_segment_words()","topicmodelingtask#filter_segment_words()","filtersegmentstask#filter_segments()","fileobject::find_or_create_by_path()","flowbots::topicmodeltrainerworkflowtest#flush_redis_cache()","displayresultstask#format_analysis()","flowbots::exceptionagent#format_exception_report()","displayresultstask#format_file_info()","llmanalysistask#format_nlp_result()","object#format_output()","llmanalysistask#generate_analysis_prompt()","flowbots::exceptionagent#generate_exception_prompt()","object#get_object_attributes()","object#get_object_bucket()","object#get_object_by_name()","object#get_object_collections()","object#get_object_indexed_attributes()","object#get_object_references()","object#get_objects()","object#get_objects_by_collection()","object#get_objects_by_query()","object#get_objects_by_reference()","object#get_objects_by_regex()","flowbots::workflows#get_workflows()","flowbots::exceptionhandler::handle_exception()","flowiseapiclient#handle_response()","flowbots::texttaggerprocessor#identify_speech_acts()","task::in_progress()","flowbots::topicmodelprocessor#infer_topics()","flowbots::initialize()","fileobject::latest()","flowbots::workflows#list_and_select()","flowbots::load_components()","cartridge#load_content()","flowbots::texttaggerprocessor#load_engtagger()","flowbots::topicmodelprocessor#load_existing_model()","flowbots::exceptionagent#load_file_structure()","flowbots::grammarprocessor#load_grammar()","flowbots::nlpprocessor#load_model()","flowbots::topicmodelprocessor#load_or_create_model()","workflowagent#load_state()","flowbots::task::load_tasks()","flowbots::workflows::load_workflows()","flowbots::exceptionhandler::log_exception()","logging::log_level()","logging#logger()","logging::logger_for()","object#main()","markdownyaml::document0#markdown_content()","flowbots::exceptionagent::new()","flowbots::fileloader::new()","flowbots::grammarprocessor::new()","flowbots::nlpprocessor::new()","flowbots::task::new()","flowbots::textprocessingworkflow::new()","flowbots::textprocessor::new()","flowbots::textsegmentprocessor::new()","flowbots::texttaggerprocessor::new()","flowbots::texttokenizeprocessor::new()","flowbots::topicmodelprocessor::new()","flowbots::topicmodeltrainerworkflow::new()","flowbots::topicmodeltrainerworkflowtest::new()","flowbots::workflows::new()","flowiseapiclient::new()","redisconnection::new()","sublayer::actions::runtestcommandaction::new()","sublayer::actions::speechtotextaction::new()","sublayer::actions::texttospeechaction::new()","sublayer::actions::writefileaction::new()","tty::promptx::new()","workflowagent::new()","workfloworchestrator::new()","markdownyaml::yamlfrontmatter1#newline1()","markdownyaml::yamlfrontmatter1#newline2()","flowbots::exceptionhandler::notify_exception()","ui::open_settings()","flowbots::grammarprocessor#parse()","flowbots::fileloader#parse_pdf()","task::pending()","flowbots::textprocessingworkflow#perform_additional_tasks()","cursor::pos()","flowiseapiclient#predict()","flowbots::nlpprocessor#process()","flowbots::textprocessor#process()","flowbots::textsegmentprocessor#process()","flowbots::texttaggerprocessor#process()","flowbots::texttokenizeprocessor#process()","workflowagent#process()","flowbots::textprocessingworkflow#process_batch()","flowbots::topicmodeltrainerworkflowtest#process_batch()","flowbots::exceptionagent#process_exception()","flowbots::topicmodeltrainerworkflowtest#process_files()","flowbots::textprocessingworkflow#process_single_file()","flowbots::cli#process_text()","flowbots::textprocessingworkflow#prompt_for_file()","flowbots::topicmodeltrainerworkflow#prompt_for_folder()","flowbots::topicmodeltrainerworkflowtest#prompt_for_folder()","tty::promptx#readline()","agent#reflect()","llmanalysistask#retrieve_file_metadata()","topicmodelingtask#retrieve_filtered_words()","accumulatefilteredsegmentstask#retrieve_input()","displayresultstask#retrieve_input()","fileloadertask#retrieve_input()","filtersegmentstask#retrieve_input()","llmanalysistask#retrieve_input()","loadtextfilestask#retrieve_input()","nlpanalysistask#retrieve_input()","preprocesstextfiletask#retrieve_input()","task#retrieve_input()","textsegmenttask#retrieve_input()","texttaggertask#retrieve_input()","tokenizesegmentstask#retrieve_input()","topicmodelingtask#retrieve_input()","agent#retrieve_memories()","llmanalysistask#retrieve_nlp_result()","fileobject#retrieve_segment_texts()","fileobject#retrieve_segments()","fileobject#retrieve_word_texts()","segment#retrieve_word_texts()","fileobject#retrieve_words()","segment#retrieve_words()","markdownyaml#root()","flowbots::textprocessingworkflow#run()","flowbots::topicmodeltrainerworkflow#run()","flowbots::topicmodeltrainerworkflowtest#run()","flowbots::workflows#run()","ui::run_workflow()","workfloworchestrator#run_workflow()","flowbots::topicmodelprocessor#save_model()","workflowagent#save_state()","flowbots::textsegmentprocessor#segment_array()","flowbots::textsegmentprocessor#segment_string()","flowbots::workflows#select_workflow()","flowbots::setup_redis()","flowbots::topicmodeltrainerworkflowtest#setup_workflow()","flowbots::shutdown()","api#splat_sort()","ui::start()","ui::start_workflow()","flowbots::stop_running_workflows()","fileloadertask#store_fileobject_id()","llmanalysistask#store_analysis_result()","agent#store_episodic_memory()","flowbots::fileloader#store_file_data()","preprocesstextfiletask#store_preprocessed_data()","texttaggertask#store_result()","textsegmenttask#store_segments()","loadtextfilestask#store_textfile_id()","topicmodelingtask#store_topic_result()","flowbots::texttokenizeprocessor#tokenize_array()","flowbots::texttokenizeprocessor#tokenize_string()","flowbots::topicmodelprocessor#train_model()","flowbots::cli#train_topic_model()","flowbots::topicmodeltrainerworkflow#train_topic_model()","flowbots::topicmodeltrainerworkflowtest#train_topic_model()","accumulatefilteredsegmentstask#update_file_object()","nlpanalysistask#update_segment_with_nlp_data()","agent#update_semantic_memory()","workflowagent#update_state()","flowiseapiclient#upsert_document()","flowbots::cli#version()","ui::view_logs()","flowbots::cli#workflows()","flowbots::exceptionagent#write_markdown_report()","llmanalysistask#write_markdown_report()","markdownyaml::document0#yaml_front_matter()","",""],"info":[["API","","API.html","","<p>This class defines the API for the Flowbots application.\n<p>It provides endpoints for accessing and manipulating …\n"],["AccumulateFilteredSegmentsTask","","AccumulateFilteredSegmentsTask.html","","<p>Task to accumulate filtered segments from all processed files.\n"],["Agent","","Agent.html","","<p>This file defines the Ohm models used in the Flowbots application.\n"],["Cartridge","","Cartridge.html","","<p>Defines the Cartridge model.\n"],["Cursor","","Cursor.html","","<p>Provides helper methods for cursor positioning and terminal interaction.\n"],["DisplayResultsTask","","DisplayResultsTask.html","","<p>This task displays the results of the text processing workflow.\n"],["FileLoaderTask","","FileLoaderTask.html","","<p>This task loads a text file and stores its ID in Redis.\n"],["FileObject","","FileObject.html","","<p>Defines the FileObject model.\n"],["FilterSegmentsTask","","FilterSegmentsTask.html","","<p>lib/tasks/filter_segments_task.rb\n"],["Flowbots","","Flowbots.html","","<p>Module for Flowbots application.\n"],["Flowbots::CLI","","Flowbots/CLI.html","","<p>This class provides a command-line interface (CLI) for interacting with the Flowbots application.\n"],["Flowbots::ExceptionAgent","","Flowbots/ExceptionAgent.html","","<p>This class handles exceptions in the Flowbots application.\n"],["Flowbots::ExceptionHandler","","Flowbots/ExceptionHandler.html","","<p>This class handles exceptions in the Flowbots application.\n"],["Flowbots::FileLoader","","Flowbots/FileLoader.html","","<p>This class handles loading and processing text files.\n"],["Flowbots::FileNotFoundError","","Flowbots/FileNotFoundError.html","","<p>Custom error class for workflow file not found.\n"],["Flowbots::GrammarProcessor","","Flowbots/GrammarProcessor.html","","<p>This class handles parsing text using a specified grammar.\n"],["Flowbots::NLPProcessor","","Flowbots/NLPProcessor.html","","<p>This class provides functionality for performing natural language processing (NLP) analysis on text. …\n"],["Flowbots::Task","","Flowbots/Task.html","","<p>This module encapsulates tasks used in Flowbots workflows.\n"],["Flowbots::TaskNotFoundError","","Flowbots/TaskNotFoundError.html","","<p>Custom error class for task not found.\n"],["Flowbots::TextProcessingWorkflow","","Flowbots/TextProcessingWorkflow.html","","<p>This class defines a workflow for processing text files, either individually or in batch mode.\nIt utilizes ...\n"],["Flowbots::TextProcessor","","Flowbots/TextProcessor.html","","<p>This class provides a base class for text processors in the Flowbots application.\n"],["Flowbots::TextSegmentProcessor","","Flowbots/TextSegmentProcessor.html","","<p>This class provides functionality for segmenting text into smaller units.\n"],["Flowbots::TextTaggerProcessor","","Flowbots/TextTaggerProcessor.html","","<p>This class provides functionality for tagging text using the EngTagger library.\n"],["Flowbots::TextTokenizeProcessor","","Flowbots/TextTokenizeProcessor.html","","<p>This class provides functionality for tokenizing text.\n"],["Flowbots::TopicModelProcessor","","Flowbots/TopicModelProcessor.html","","<p>This class provides functionality for processing text using a topic model.\n"],["Flowbots::TopicModelTrainerWorkflow","","Flowbots/TopicModelTrainerWorkflow.html","","<p>This class defines a workflow for training a topic model using a collection of text files.\nIt utilizes ...\n"],["Flowbots::TopicModelTrainerWorkflowtest","","Flowbots/TopicModelTrainerWorkflowtest.html","",""],["Flowbots::Workflows","","Flowbots/Workflows.html","","<p>This class manages workflows in the Flowbots application.\n"],["FlowiseApiClient","","FlowiseApiClient.html","","<p>This class provides an interface for interacting with the Flowise API.\n"],["Jongleur","","Jongleur.html","",""],["Jongleur::WorkerTask","","Jongleur/WorkerTask.html","","<p>Jongleur::WorkerTask is a class that defines a task to be executed by Jongleur.\n"],["Lemma","","Lemma.html","","<p>Defines the Lemma model.\n"],["LlmAnalysisTask","","LlmAnalysisTask.html","","<p>This task performs LLM analysis on a text file using a pre-trained model.\n"],["LoadTextFilesTask","","LoadTextFilesTask.html","","<p>Task to load text files and store their IDs in Redis.\n"],["Logging","","Logging.html","",""],["MarkdownYaml","","MarkdownYaml.html","","<p>Autogenerated from a Treetop grammar. Edits may be lost.\n"],["MarkdownYaml::Document0","","MarkdownYaml/Document0.html","","<p>The Document node represents the entire document structure.\nIt contains the YAML front matter and the ...\n"],["MarkdownYaml::YamlFrontMatter0","","MarkdownYaml/YamlFrontMatter0.html","","<p>The YamlFrontMatter node represents the YAML front matter section.\n"],["MarkdownYaml::YamlFrontMatter1","","MarkdownYaml/YamlFrontMatter1.html","","<p>The YamlFrontMatter node represents the YAML front matter section.\n"],["MarkdownYamlParser","","MarkdownYamlParser.html","","<p>The MarkdownYamlParser class is responsible for parsing the Markdown YAML grammar.\n"],["MonadicError","","MonadicError.html","","<p>Defines a custom error class for monadic errors.\n"],["NlpAnalysisTask","","NlpAnalysisTask.html","","<p>This task performs natural language processing (NLP) analysis on the segments of a text file.\n"],["Object","","Object.html","",""],["PreprocessTextFileTask","","PreprocessTextFileTask.html","","<p>This task preprocesses a text file, extracting metadata and cleaning the content.\n"],["RedisConnection","","RedisConnection.html","","<p>Class to manage Redis connection.\n"],["Segment","","Segment.html","","<p>Defines the Segment model.\n"],["Sublayer","","Sublayer.html","","<p>blueprints.sublayer.com/blueprints/70562717-70c5-4406-a792-358d169f9f0b\n"],["Sublayer::Actions","","Sublayer/Actions.html","",""],["Sublayer::Actions::RunTestCommandAction","","Sublayer/Actions/RunTestCommandAction.html","",""],["Sublayer::Actions::SpeechToTextAction","","Sublayer/Actions/SpeechToTextAction.html","",""],["Sublayer::Actions::TextToSpeechAction","","Sublayer/Actions/TextToSpeechAction.html","",""],["Sublayer::Actions::WriteFileAction","","Sublayer/Actions/WriteFileAction.html","",""],["TTY","","TTY.html","","<p>Extends the TTY::Prompt class with custom functionality.\n"],["TTY::Markdown","","TTY/Markdown.html","","<p>Provides functionality for converting Markdown to terminal-friendly output.\n"],["TTY::Markdown::Converter","","TTY/Markdown/Converter.html","","<p>A converter class for converting Kramdown::Document trees to terminal output.\n"],["TTY::PromptX","","TTY/PromptX.html","","<p>A custom prompt class with enhanced features.\n"],["Task","","Task.html","","<p>Defines the Task model.\n"],["TextSegmentTask","","TextSegmentTask.html","","<p>This task segments the text content of a Textfile into smaller units.\n"],["TextTaggerTask","","TextTaggerTask.html","","<p>This class performs text tagging on a given text.\n"],["TextTokenizeTask","","TextTokenizeTask.html","","<p>This task tokenizes the segments of a text file.\n"],["TokenizeSegmentsTask","","TokenizeSegmentsTask.html","","<p>This task tokenizes the segments of a text file.\n"],["Topic","","Topic.html","","<p>Defines the Topic model.\n"],["TopicModelingTask","","TopicModelingTask.html","","<p>This task performs topic modeling on a text file using a pre-trained model.\n"],["TrainTopicModelTask","","TrainTopicModelTask.html","","<p>This task trains a topic model using filtered segments from multiple batches.\n"],["UI","","UI.html","","<p>Provides user interface functionality for the Flowbots application.\n"],["Word","","Word.html","","<p>Defines the Word model.\n"],["WorkflowAgent","","WorkflowAgent.html","","<p>This class represents an agent in a workflow.\nClass representing an individual agent within a workflow ...\n"],["WorkflowOrchestrator","","WorkflowOrchestrator.html","","<p>Orchestrates the execution of workflows in the Flowbots application.\n<p>The WorkflowOrchestrator is responsible …\n"],["_nt_document","MarkdownYaml","MarkdownYaml.html#method-i-_nt_document","()","<p>Parses the document node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed document node.\n"],["_nt_markdown_content","MarkdownYaml","MarkdownYaml.html#method-i-_nt_markdown_content","()","<p>Parses the Markdown content node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed Markdown content node. …\n"],["_nt_newline","MarkdownYaml","MarkdownYaml.html#method-i-_nt_newline","()","<p>Parses the newline node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed newline node.\n"],["_nt_yaml_front_matter","MarkdownYaml","MarkdownYaml.html#method-i-_nt_yaml_front_matter","()","<p>Parses the YAML front matter node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed YAML front matter …\n"],["add_agent","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-add_agent","(role, cartridge_file, author: \"@b08x\")","<p>Adds an agent to the orchestrator.\n<p>@param role [String] The role of the agent in the workflow.\n@param ...\n"],["add_lemma","FileObject","FileObject.html#method-i-add_lemma","(lemma_data)","<p>Adds a new lemma to the FileObject.\n<p>@param lemma_data [Hash] A hash containing lemma data.\n<p>@return [Lemma] …\n"],["add_lemmas","FileObject","FileObject.html#method-i-add_lemmas","(lemmas_data)","<p>Adds multiple lemmas to the FileObject.\n<p>@param lemmas_data [Array&lt;Hash&gt;] An array of lemma data …\n"],["add_lemmas_to_textfile","NlpAnalysisTask","NlpAnalysisTask.html#method-i-add_lemmas_to_textfile","(textfile, lemma_counts)","<p>Adds lemmas to a FileObject.\n<p>Converts the lemma counts hash to an array of lemma data and adds it to the …\n"],["add_segment","FileObject","FileObject.html#method-i-add_segment","(text)","<p>Adds a new segment to the FileObject.\n<p>@param text [String] The text of the new segment.\n<p>@return [Segment] …\n"],["add_segments","FileObject","FileObject.html#method-i-add_segments","(new_segments)","<p>Adds multiple segments to the FileObject.\n<p>@param new_segments [Array&lt;String&gt;] An array of segment …\n"],["add_topics","FileObject","FileObject.html#method-i-add_topics","(new_topics)","<p>Adds multiple topics to the FileObject.\n<p>@param new_topics [Array&lt;String&gt;] An array of topic names. …\n"],["add_word","Segment","Segment.html#method-i-add_word","(word_data)","<p>Adds a new word to the Segment.\n<p>@param word_data [Hash] A hash containing word data.\n<p>@return [Word] The …\n"],["add_words","Segment","Segment.html#method-i-add_words","(new_words)","<p>Adds multiple words to the Segment.\n<p>@param new_words [Array&lt;Hash&gt;] An array of word data hashes. …\n"],["add_words_to_segment","NlpAnalysisTask","NlpAnalysisTask.html#method-i-add_words_to_segment","(segment, processed_tokens)","<p>Adds processed words to a segment.\n<p>Extracts word information from the processed tokens and adds it to …\n"],["after_delete","FileObject","FileObject.html#method-i-after_delete","()","<p>Removes the FileObject’s ID from the Redis set for latest FileObjects.\n<p>@return [void]\n"],["after_save","FileObject","FileObject.html#method-i-after_save","()","<p>Adds the FileObject’s ID to the Redis set for latest FileObjects.\n<p>@return [void]\n"],["analyze_transitivity","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-analyze_transitivity","(text)","<p>Analyzes the transitivity of sentences in the given text.\n<p>@param text [String] The text to analyze.\n<p>@return …\n"],["call","Sublayer::Actions::RunTestCommandAction","Sublayer/Actions/RunTestCommandAction.html#method-i-call","()",""],["call","Sublayer::Actions::SpeechToTextAction","Sublayer/Actions/SpeechToTextAction.html#method-i-call","()",""],["call","Sublayer::Actions::TextToSpeechAction","Sublayer/Actions/TextToSpeechAction.html#method-i-call","()",""],["call","Sublayer::Actions::WriteFileAction","Sublayer/Actions/WriteFileAction.html#method-i-call","()","<p>Writes the contents to the file in binary mode\n@return [void]\n"],["classify_file","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-classify_file","(file_path)","<p>Classifies the file type based on its MIME type.\n<p>@param file_path [String] The path to the file.\n<p>@return …\n"],["clean_segments","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-clean_segments","(segments)","<p>Cleans the given segments by removing unwanted segments and words.\n<p>@param segments [Array&lt;Array&lt;String&gt;&gt;] …\n"],["clean_segments_for_modeling","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-clean_segments_for_modeling","(segments)","<p>Cleans the segments for topic modeling by removing unwanted segments and words.\n<p>@param segments [Array&lt;Array&lt;String&gt;&gt;] …\n"],["clean_segments_for_modeling","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-clean_segments_for_modeling","(segments)",""],["cleanup","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-cleanup","()","<p>Performs cleanup operations for the workflow.\n<p>This method is called after the workflow has finished or …\n"],["complete","Task","Task.html#method-i-complete","(result = nil)","<p>Completes the task and updates its status and result.\n<p>@param result [Object] The result of the task execution. …\n"],["completed","Task","Task.html#method-c-completed","()","<p>Finds all completed tasks.\n<p>@return [Array&lt;Task&gt;] An array of completed tasks.\n"],["configure_logger_for","Logging","Logging.html#method-c-configure_logger_for","(_classname, _methodname)","<p>Configures a logger for the specified class and method.\n<p>@param &lt;em&gt;classname [String] The name of …\n"],["convert_p","TTY::Markdown::Converter","TTY/Markdown/Converter.html#method-i-convert_p","(ell, opts)","<p>Converts a paragraph element to terminal output.\n<p>@param ell [Kramdown::Element] The paragraph element …\n"],["create_doc","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-create_doc","(segment)","<p>Creates a Spacy::Doc object from the given segment’s tokens.\n<p>@param segment [Segment] The Segment …\n"],["create_new_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-create_new_model","()","<p>Creates a new topic model with the specified parameters.\n<p>@return [void]\n"],["create_or_fetch_file_object","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-create_or_fetch_file_object","(file_path)","<p>Creates or fetches a FileObject for the given file path.\n<p>@param file_path [String, Hash] The path to the …\n"],["create_with_timestamp","Task","Task.html#method-c-create_with_timestamp","(attributes = {})","<p>Creates a new Task instance with a timestamp.\n<p>@param attributes [Hash] A hash of attributes for the new …\n"],["current_batch","FileObject","FileObject.html#method-c-current_batch","()","<p>Retrieves all FileObjects from the current batch.\n<p>@return [Array&lt;FileObject&gt;] An array of FileObjects …\n"],["custom_workflow","UI","UI.html#method-c-custom_workflow","()","<p>Creates a custom workflow.\n<p>Prompts the user for a workflow name and tasks, and displays the created workflow. …\n"],["define_workflow","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-define_workflow","(workflow_definition)","<p>Defines the workflow structure using a task graph.\n<p>The workflow definition is a hash that outlines the …\n"],["display_filtered_segments","FilterSegmentsTask","FilterSegmentsTask.html#method-i-display_filtered_segments","(filtered_segments)","<p>Displays the filtered segments to the user.\n<p>@param filtered_segments [Array&lt;Array&lt;String&gt;&gt;] …\n"],["display_results","DisplayResultsTask","DisplayResultsTask.html#method-i-display_results","(textfile, analysis_result)","<p>Displays the results of the text processing workflow.\n<p>@param textfile [Textfile] The processed Textfile …\n"],["display_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-i-display_workflows","(workflows)","<p>Displays a list of available workflows in a table format.\n<p>@param workflows [Array&lt;Array(String, String …\n"],["duration","Task","Task.html#method-i-duration","()","<p>Returns the duration of the task in seconds.\n<p>@return [Integer] The duration of the task in seconds, or …\n"],["edit_api_settings","UI","UI.html#method-c-edit_api_settings","()","<p>Edits API settings.\n<p>Displays a placeholder message indicating the API settings editor.\n<p>@return [void]\n"],["edit_general_settings","UI","UI.html#method-c-edit_general_settings","()","<p>Edits general settings.\n<p>Displays a placeholder message indicating the general settings editor.\n<p>@return …\n"],["edit_workflow_settings","UI","UI.html#method-c-edit_workflow_settings","()","<p>Edits workflow settings.\n<p>Displays a placeholder message indicating the workflow settings editor.\n<p>@return …\n"],["ensure_model_exists","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-ensure_model_exists","()","<p>Ensures that the topic model exists, loading or creating it if necessary.\n<p>@return [void]\n"],["evaluate","Cartridge","Cartridge.html#method-i-evaluate","(input)","<p>Evaluate the cartridge content (implementation depends on the cartridge format).\n<p>@param input [String] …\n"],["execute","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-execute","()","<p>Executes the task to accumulate and clean filtered segments.\n<p>Retrieves filtered segments from Redis, cleans …\n"],["execute","DisplayResultsTask","DisplayResultsTask.html#method-i-execute","()","<p>Executes the task to display the results of the text processing workflow.\n<p>Retrieves the processed Textfile …\n"],["execute","FileLoaderTask","FileLoaderTask.html#method-i-execute","()","<p>Executes the task to load a FileObject and store its ID in Redis.\n<p>Retrieves the input file path, processes …\n"],["execute","FilterSegmentsTask","FilterSegmentsTask.html#method-i-execute","()","<p>Executes the segment filtering task.\n<p>Retrieves the file object, filters segments based on word tags,\nstores ...\n"],["execute","Flowbots::Task","Flowbots/Task.html#method-i-execute","()","<p>Executes the task.\n<p>This method must be implemented in subclasses.\n<p>@return [void]\n@raise [NotImplementedError] ...\n"],["execute","LlmAnalysisTask","LlmAnalysisTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","LoadTextFilesTask","LoadTextFilesTask.html#method-i-execute","()","<p>Executes the task to load a text file using the Flowbots::FileLoader.\n<p>Retrieves the file path from Redis …\n"],["execute","NlpAnalysisTask","NlpAnalysisTask.html#method-i-execute","()","<p>Executes the task.\n<p>Retrieves the FileObject from Redis, processes each segment using the NLPProcessor …\n"],["execute","PreprocessTextFileTask","PreprocessTextFileTask.html#method-i-execute","()","<p>Executes the text file preprocessing task.\n<p>Retrieves the text file object, parses it using a custom grammar, …\n"],["execute","Task","Task.html#method-i-execute","()","<p>Executes the task.\n<p>This method must be implemented in subclasses to define the specific\nactions performed ...\n"],["execute","TextSegmentTask","TextSegmentTask.html#method-i-execute","()","<p>Executes the task to segment the text content of a FileObject.\n<p>Retrieves the FileObject from Redis, extracts …\n"],["execute","TextTaggerTask","TextTaggerTask.html#method-i-execute","()","<p>Executes the text tagging task.\n<p>Retrieves the FileObject from Redis, extracts its preprocessed content, …\n"],["execute","TextTokenizeTask","TextTokenizeTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TokenizeSegmentsTask","TokenizeSegmentsTask.html#method-i-execute","()","<p>Executes the task to tokenize the segments of a FileObject.\n<p>Retrieves the FileObject from Redis, tokenizes …\n"],["execute","TopicModelingTask","TopicModelingTask.html#method-i-execute","()","<p>Executes the task to perform topic modeling on a FileObject.\n<p>Retrieves the FileObject from Redis, extracts …\n"],["execute","TrainTopicModelTask","TrainTopicModelTask.html#method-i-execute","()","<p>Executes the task to train a topic model using accumulated filtered segments.\n<p>Retrieves the current batch …\n"],["exit_on_failure?","Flowbots::CLI","Flowbots/CLI.html#method-c-exit_on_failure-3F","()","<p>Defines whether the CLI should exit with a non-zero status code when an error occurs.\n<p>@return [Boolean] …\n"],["extract_main_topics","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-extract_main_topics","(text, limit=5)","<p>Extracts the main topics from the given text.\n<p>@param text [String] The text to extract topics from.\n@param ...\n"],["extract_markdown_content","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-extract_markdown_content","(parse_result)","<p>Extracts the Markdown content from the parse result.\n<p>@param parse_result [Treetop::Runtime::SyntaxNode] …\n"],["extract_metadata","PreprocessTextFileTask","PreprocessTextFileTask.html#method-i-extract_metadata","(yaml_front_matter)","<p>Extracts metadata from the YAML front matter of the parsed text file.\n<p>@param yaml_front_matter [String] …\n"],["extract_relevant_files","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-extract_relevant_files","(exception)","<p>Extracts relevant files from the exception backtrace.\n<p>@param exception [Exception] The exception object. …\n"],["extract_text","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-extract_text","(file_type, file_path)","<p>Extracts the text content from a file based on its type.\n<p>@param file_type [Symbol] The file type.\n@param ...\n"],["extract_text_json","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-extract_text_json","(file_path)",""],["extract_workflow_description","Flowbots::Workflows","Flowbots/Workflows.html#method-i-extract_workflow_description","(file)","<p>Extracts the description of a workflow from its file.\nThe description is assumed to be the first line ...\n"],["extract_yaml_front_matter","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-extract_yaml_front_matter","(parse_result)","<p>Extracts the YAML front matter from the parse result.\n<p>@param parse_result [Treetop::Runtime::SyntaxNode] …\n"],["fail","Task","Task.html#method-i-fail","(error_message)","<p>Fails the task and updates its status and result with an error message.\n<p>@param error_message [String] …\n"],["failed","Task","Task.html#method-c-failed","()","<p>Finds all failed tasks.\n<p>@return [Array&lt;Task&gt;] An array of failed tasks.\n"],["fallback_exception_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-fallback_exception_report","(exception_details)","<p>Generates a fallback exception report if the agent fails to generate a report.\n<p>@param exception_details …\n"],["fetch_unprocessed_file_ids","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-fetch_unprocessed_file_ids","()","<p>Fetches the IDs of unprocessed files.\n<p>@return [Array&lt;Integer&gt;] An array of unprocessed file IDs …\n"],["filter_segment_words","FilterSegmentsTask","FilterSegmentsTask.html#method-i-filter_segment_words","(segment)","<p>Filters words from a segment based on relevant parts of speech (POS) tags.\n<p>@param segment [Segment] The …\n"],["filter_segment_words","TopicModelingTask","TopicModelingTask.html#method-i-filter_segment_words","(segment)","<p>Filters words from a segment based on their POS tags.\n<p>@param segment [Segment] The segment to filter words …\n"],["filter_segments","FilterSegmentsTask","FilterSegmentsTask.html#method-i-filter_segments","(file_object)","<p>Filters segments based on their word tags.\n<p>@param file_object [FileObject] The file object containing …\n"],["find_or_create_by_path","FileObject","FileObject.html#method-c-find_or_create_by_path","(file_path, attributes = {})","<p>Finds or creates a new FileObject instance based on the file path.\n<p>@param file_path [String] The path …\n"],["flush_redis_cache","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-flush_redis_cache","()",""],["format_analysis","DisplayResultsTask","DisplayResultsTask.html#method-i-format_analysis","(analysis_result)","<p>Formats the analysis results for display.\n<p>@param analysis_result [String, Hash] The LLM analysis results. …\n"],["format_exception_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-format_exception_report","(agent_response, exception_details)","<p>Formats the exception report based on the agent’s response.\n<p>@param agent_response [String] The response …\n"],["format_file_info","DisplayResultsTask","DisplayResultsTask.html#method-i-format_file_info","(textfile)","<p>Formats the file information for display.\n<p>@param textfile [Textfile] The processed Textfile object.\n<p>@return …\n"],["format_nlp_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-format_nlp_result","(nlp_result)","<p>Formats the NLP results for display in the prompt.\n<p>@param nlp_result [Array] The NLP results for the segments …\n"],["format_output","Object","Object.html#method-i-format_output","(objects)",""],["generate_analysis_prompt","LlmAnalysisTask","LlmAnalysisTask.html#method-i-generate_analysis_prompt","(textfile, content, metadata, nlp_result)","\n<pre>Please structure your response in a clear, concise manner. Thank you!</pre>\n<p>PROMPT\nend\n"],["generate_exception_prompt","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-generate_exception_prompt","(exception_details)","<p>Generates a prompt for the exception handler agent.\n<p>@param exception_details [Hash] A hash containing …\n"],["get_object_attributes","Object","Object.html#method-i-get_object_attributes","(object_bucket)",""],["get_object_bucket","Object","Object.html#method-i-get_object_bucket","(object_bucket)",""],["get_object_by_name","Object","Object.html#method-i-get_object_by_name","(object_bucket, object_name)",""],["get_object_collections","Object","Object.html#method-i-get_object_collections","(object_bucket)",""],["get_object_indexed_attributes","Object","Object.html#method-i-get_object_indexed_attributes","(object_bucket)",""],["get_object_references","Object","Object.html#method-i-get_object_references","(object_bucket)",""],["get_objects","Object","Object.html#method-i-get_objects","(object_bucket, object_name, query=nil)",""],["get_objects_by_collection","Object","Object.html#method-i-get_objects_by_collection","(object_bucket, collection_name)",""],["get_objects_by_query","Object","Object.html#method-i-get_objects_by_query","(object_bucket, query)",""],["get_objects_by_reference","Object","Object.html#method-i-get_objects_by_reference","(object_bucket, reference_name, reference_value)",""],["get_objects_by_regex","Object","Object.html#method-i-get_objects_by_regex","(object_bucket, regex)",""],["get_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-i-get_workflows","()","<p>Retrieves a list of available workflows from the WORKFLOW_DIR directory.\n<p>@return [Array&lt;Array(String …\n"],["handle_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-handle_exception","(classname=nil, exception)","<p>Handles an exception by generating a report and notifying relevant parties.\n<p>@param classname [String] …\n"],["handle_response","FlowiseApiClient","FlowiseApiClient.html#method-i-handle_response","(response)","<p>Handles the response from the Flowise API.\n<p>@param response [Faraday::Response] The response from the  …\n"],["identify_speech_acts","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-identify_speech_acts","(text)","<p>Identifies the speech acts in the given text.\n<p>@param text [String] The text to analyze.\n<p>@return [Array] …\n"],["in_progress","Task","Task.html#method-c-in_progress","()","<p>Finds all tasks in progress.\n<p>@return [Array&lt;Task&gt;] An array of tasks in progress.\n"],["infer_topics","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-infer_topics","(document)","<p>Infers the topics for a given document.\n<p>@param document [String] The document to infer topics for.\n<p>@return …\n"],["initialize","Flowbots","Flowbots.html#method-c-initialize","()","<p>Initializes the Flowbots application.\n<p>@return [void]\n"],["latest","FileObject","FileObject.html#method-c-latest","(limit = nil)","<p>Retrieves the latest FileObject from Redis.\n<p>@param limit [Integer] The maximum number of FileObjects to …\n"],["list_and_select","Flowbots::Workflows","Flowbots/Workflows.html#method-i-list_and_select","()","<p>Lists available workflows and allows the user to select one.\n<p>@return [String, nil] The name of the selected …\n"],["load_components","Flowbots","Flowbots.html#method-c-load_components","()","<p>Loads the necessary components for the application.\n<p>@return [void]\n"],["load_content","Cartridge","Cartridge.html#method-i-load_content","()","<p>Load the cartridge content from the file.\n<p>@return [Hash] The loaded cartridge content as a hash.\n"],["load_engtagger","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-load_engtagger","()","<p>Loads the EngTagger library.\n<p>@return [void]\n"],["load_existing_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-load_existing_model","()","<p>Loads an existing topic model from the specified path.\n<p>@return [void]\n"],["load_file_structure","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-load_file_structure","()","<p>Loads the file structure from the flowbots.json file.\n<p>@return [Hash] The file structure.\n"],["load_grammar","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-load_grammar","()","<p>Loads the grammar file and creates a parser instance.\n<p>@return [void]\n"],["load_model","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-load_model","()","<p>Loads the NLP model from the specified environment variable.\n<p>@return [void]\n"],["load_or_create_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-load_or_create_model","()","<p>Loads an existing topic model or creates a new one if it doesn’t exist.\n<p>@return [void]\n"],["load_state","WorkflowAgent","WorkflowAgent.html#method-i-load_state","()","<p>Loads the agent’s state from Redis.\n<p>@return [void]\n"],["load_tasks","Flowbots::Task","Flowbots/Task.html#method-c-load_tasks","()","<p>Loads all task files from the TASK_DIR directory.\n<p>@return [void]\n"],["load_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-c-load_workflows","()","<p>Class method to load all workflow files from the WORKFLOW_DIR directory.\nIt also checks for user-defined ...\n"],["log_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-log_exception","(exception)","<p>Logs an exception to the application’s logger.\n<p>@param exception [Exception] The exception object. …\n"],["log_level","Logging","Logging.html#method-c-log_level","()","<p>Returns the default log level.\n<p>@return [Integer] The log level.\n"],["logger","Logging","Logging.html#method-i-logger","()","<p>Returns the logger for the current class and method.\n<p>@return [Logger] The logger object.\n"],["logger_for","Logging","Logging.html#method-c-logger_for","(classname, methodname)","<p>Returns the logger for the specified class and method.\n<p>@param classname [String] The name of the class. …\n"],["main","Object","Object.html#method-i-main","()",""],["markdown_content","MarkdownYaml::Document0","MarkdownYaml/Document0.html#method-i-markdown_content","()","<p>The Markdown content section of the document.\n<p>@return [Treetop::Runtime::SyntaxNode] The Markdown content …\n"],["new","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-c-new","()","<p>Initializes a new instance of the ExceptionAgent class.\n<p>@return [void]\n"],["new","Flowbots::FileLoader","Flowbots/FileLoader.html#method-c-new","(file_path)","<p>Initializes a new FileLoader instance.\n<p>@param file_path [String] The path to the file to be loaded.\n<p>@return …\n"],["new","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-c-new","(grammar_name)","<p>Initializes a new GrammarProcessor instance.\n<p>@param grammar_name [String] The name of the grammar to use …\n"],["new","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-c-new","()","<p>Initializes a new NLPProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::Task","Flowbots/Task.html#method-c-new","(options={})","<p>Initializes a new Task instance.\n<p>@param options [Hash] A hash of options for the task.\n<p>@return [void]\n"],["new","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-c-new","(input_file_path=nil, batch_mode=false)","<p>Initializes a new TextProcessingWorkflow instance.\n<p>@param input_file_path [String, nil] The path to the …\n"],["new","Flowbots::TextProcessor","Flowbots/TextProcessor.html#method-c-new","()","<p>Initializes a new TextProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-c-new","()","<p>Initializes a new TextSegmentProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-c-new","()","<p>Initializes a new TextTaggerProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-c-new","()","<p>Initializes a new TextTokenizeProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-c-new","()","<p>Initializes a new TopicModelProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-c-new","(input_folder_path=nil)","<p>Initializes a new TopicModelTrainerWorkflow instance.\n<p>@param input_folder_path [String, nil] The path …\n"],["new","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-c-new","(input_folder_path=nil)",""],["new","Flowbots::Workflows","Flowbots/Workflows.html#method-c-new","()","<p>Initializes a new Workflows instance.\n<p>@return [void]\n"],["new","FlowiseApiClient","FlowiseApiClient.html#method-c-new","(base_url)","<p>Initializes a new FlowiseApiClient instance.\n<p>@param base_url [String] The base URL of the Flowise API …\n"],["new","RedisConnection","RedisConnection.html#method-c-new","()","<p>Initializes a new RedisConnection instance.\n<p>@return [void]\n"],["new","Sublayer::Actions::RunTestCommandAction","Sublayer/Actions/RunTestCommandAction.html#method-c-new","(test_command:)",""],["new","Sublayer::Actions::SpeechToTextAction","Sublayer/Actions/SpeechToTextAction.html#method-c-new","(audio_data)",""],["new","Sublayer::Actions::TextToSpeechAction","Sublayer/Actions/TextToSpeechAction.html#method-c-new","(text)",""],["new","Sublayer::Actions::WriteFileAction","Sublayer/Actions/WriteFileAction.html#method-c-new","(file_contents:, file_path:)","<p>Initializes the action with the contents to write and the target file path\n@param [String] file_contents ...\n"],["new","TTY::PromptX","TTY/PromptX.html#method-c-new","(active_color:, prefix:, history: true)","<p>Initializes a new PromptX instance.\n<p>@param active_color [Symbol] The color for the active prompt.\n@param ...\n"],["new","WorkflowAgent","WorkflowAgent.html#method-c-new","(role, cartridge_file)","<p>Initializes a new WorkflowAgent instance.\n<p>@param role [String] The role of the agent.\n@param cartridge_file ...\n"],["new","WorkflowOrchestrator","WorkflowOrchestrator.html#method-c-new","()","<p>Initializes a new WorkflowOrchestrator instance.\n<p>@return [void]\n"],["newline1","MarkdownYaml::YamlFrontMatter1","MarkdownYaml/YamlFrontMatter1.html#method-i-newline1","()","<p>The first newline character after the “—” delimiter.\n<p>@return [Treetop::Runtime::SyntaxNode] …\n"],["newline2","MarkdownYaml::YamlFrontMatter1","MarkdownYaml/YamlFrontMatter1.html#method-i-newline2","()","<p>The second newline character after the “—” delimiter.\n<p>@return [Treetop::Runtime::SyntaxNode] …\n"],["notify_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-notify_exception","(report)","<p>Notifies relevant parties about an exception.\n<p>@param report [String] The formatted exception report.\n<p>@return …\n"],["open_settings","UI","UI.html#method-c-open_settings","()","<p>Opens the settings menu.\n<p>Displays a menu of settings categories and handles user selection.\n<p>@return [void] …\n"],["parse","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-parse","(text)","<p>Parses the given text using the specified grammar.\n<p>@param text [String] The text to parse.\n<p>@return [Hash, …\n"],["parse_pdf","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-parse_pdf","(file_path)","<p>Parses a PDF file and extracts its text content.\n<p>@param file_path [String] The path to the PDF file.\n<p>@return …\n"],["pending","Task","Task.html#method-c-pending","()","<p>Finds all pending tasks.\n<p>@return [Array&lt;Task&gt;] An array of pending tasks.\n"],["perform_additional_tasks","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-perform_additional_tasks","(_file_id)","<p>Performs additional tasks for the given file ID.\n<p>Defines the workflow for additional tasks and runs the …\n"],["pos","Cursor","Cursor.html#method-c-pos","()","<p>Returns the current cursor position.\n<p>@return [Hash] A hash containing the row and column of the cursor. …\n"],["predict","FlowiseApiClient","FlowiseApiClient.html#method-i-predict","(chatflow_id, options={})","<p>Sends a prediction request to the Flowise API.\n<p>@param chatflow_id [String] The ID of the chatflow to use …\n"],["process","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-process","(segment, options={})","<p>Processes the given segment using the loaded NLP model and returns a hash of processed tokens.\n<p>@param …\n"],["process","Flowbots::TextProcessor","Flowbots/TextProcessor.html#method-i-process","(text)","<p>Processes the given text.\n<p>This method must be implemented in subclasses.\n<p>@param text [String] The text …\n"],["process","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-process","(text, opts={})","<p>Segments the given text using the specified options.\n<p>@param text [String, Array] The text to be segmented. …\n"],["process","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-process","(text, options={})","<p>Processes the given text using the EngTagger library and returns a hash of tagged results.\n<p>@param text …\n"],["process","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-process","(text, opts={})","<p>Tokenizes the given text using the specified options.\n<p>@param text [String, Array] The text to be tokenized. …\n"],["process","WorkflowAgent","WorkflowAgent.html#method-i-process","(input)","<p>Processes the given input using the agent’s cartridge.\n<p>@param input [String] The input to process. …\n"],["process_batch","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-process_batch","()","<p>Processes files in batch mode.\n<p>Fetches unprocessed file IDs and performs additional tasks for each file. …\n"],["process_batch","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-process_batch","(batch_files)",""],["process_exception","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-process_exception","(classname, exception)","<p>Processes an exception and generates a report.\n<p>@param classname [String] The name of the class where the …\n"],["process_files","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-process_files","()",""],["process_single_file","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-process_single_file","()","<p>Processes a single file.\n<p>Creates or fetches the FileObject for the input file and performs additional …\n"],["process_text","Flowbots::CLI","Flowbots/CLI.html#method-i-process_text","(file)","<p>Processes a text file using the text processing workflow.\n<p>@param file [String] The path to the text file. …\n"],["prompt_for_file","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-prompt_for_file","()","<p>Prompts the user to select a file using the <code>gum file</code> command.\n<p>@return [String] The path to the selected …\n"],["prompt_for_folder","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-prompt_for_folder","()","<p>Prompts the user to select a folder using the <code>gum file</code> command.\n<p>@return [String] The path to the selected …\n"],["prompt_for_folder","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-prompt_for_folder","()",""],["readline","TTY::PromptX","TTY/PromptX.html#method-i-readline","(text = \"\")","<p>Reads a line of input from the user.\n<p>@param text [String] The text to display before the input field. …\n"],["reflect","Agent","Agent.html#method-i-reflect","(content)","<p>Record a reflection for the agent.\n<p>@param content [String] The content of the reflection.\n<p>@return [Reflection] …\n"],["retrieve_file_metadata","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_file_metadata","()","<p>Retrieves the file metadata from Redis.\n<p>@return [Hash] The file metadata.\n"],["retrieve_filtered_words","TopicModelingTask","TopicModelingTask.html#method-i-retrieve_filtered_words","(textfile)","<p>Retrieves filtered words from the segments of the given FileObject.\n<p>@param textfile [FileObject] The  …\n"],["retrieve_input","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","DisplayResultsTask","DisplayResultsTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","FileLoaderTask","FileLoaderTask.html#method-i-retrieve_input","()","<p>Retrieves the input file path from Redis.\n<p>@return [String] The input file path.\n"],["retrieve_input","FilterSegmentsTask","FilterSegmentsTask.html#method-i-retrieve_input","()","<p>Retrieves the input file object.\n<p>@return [FileObject] The retrieved file object.\n"],["retrieve_input","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_input","()",""],["retrieve_input","LoadTextFilesTask","LoadTextFilesTask.html#method-i-retrieve_input","()","<p>Retrieves the input file path from Redis.\n<p>@return [String] The input file path.\n"],["retrieve_input","NlpAnalysisTask","NlpAnalysisTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","PreprocessTextFileTask","PreprocessTextFileTask.html#method-i-retrieve_input","()","<p>Retrieves the input text file object.\n<p>@return [Textfile] The retrieved text file object.\n"],["retrieve_input","Task","Task.html#method-i-retrieve_input","()","<p>Retrieves the input file object from Redis.\n<p>@return [FileObject] The retrieved file object.\n"],["retrieve_input","TextSegmentTask","TextSegmentTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","TextTaggerTask","TextTaggerTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","TokenizeSegmentsTask","TokenizeSegmentsTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_input","TopicModelingTask","TopicModelingTask.html#method-i-retrieve_input","()","<p>Retrieves the input for the task, which is the current FileObject.\n<p>@return [FileObject] The current FileObject …\n"],["retrieve_memories","Agent","Agent.html#method-i-retrieve_memories","(type, query)","<p>Retrieve memories based on type and query.\n<p>@param type [Symbol] The type of memory to retrieve (:episodic, …\n"],["retrieve_nlp_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_nlp_result","(textfile)","<p>Retrieves the NLP results for the segments of the Textfile.\n<p>@param textfile [Textfile] The Textfile object. …\n"],["retrieve_segment_texts","FileObject","FileObject.html#method-i-retrieve_segment_texts","()","<p>Retrieves the text of all segments associated with the FileObject.\n<p>@return [Array&lt;String&gt;] An array …\n"],["retrieve_segments","FileObject","FileObject.html#method-i-retrieve_segments","()","<p>Retrieves all segments associated with the FileObject.\n<p>@return [Array&lt;Segment&gt;] An array of segments. …\n"],["retrieve_word_texts","FileObject","FileObject.html#method-i-retrieve_word_texts","()","<p>Retrieves the text of all words associated with the FileObject.\n<p>@return [Array&lt;String&gt;] An array …\n"],["retrieve_word_texts","Segment","Segment.html#method-i-retrieve_word_texts","()","<p>Retrieves the text of all words associated with the Segment.\n<p>@return [Array&lt;String&gt;] An array of …\n"],["retrieve_words","FileObject","FileObject.html#method-i-retrieve_words","()","<p>Retrieves all words associated with the FileObject.\n<p>@return [Array&lt;Word&gt;] An array of words.\n"],["retrieve_words","Segment","Segment.html#method-i-retrieve_words","()","<p>Retrieves all words associated with the Segment.\n<p>@return [Array&lt;Word&gt;] An array of words.\n"],["root","MarkdownYaml","MarkdownYaml.html#method-i-root","()","<p>The root node of the grammar.\n<p>@return [Treetop::Runtime::SyntaxNode] The root node of the grammar.\n"],["run","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-run","()","<p>Runs the text processing workflow.\n<p>Sets up the workflow, processes the file(s), and performs additional …\n"],["run","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-run","()","<p>Runs the topic model trainer workflow.\n<p>Sets up the workflow, processes the files, and trains the topic …\n"],["run","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-run","()",""],["run","Flowbots::Workflows","Flowbots/Workflows.html#method-i-run","(workflow_name)","<p>Runs the specified workflow.\n<p>@param workflow_name [String] The name of the workflow to run.\n<p>@return [void] …\n"],["run_workflow","UI","UI.html#method-c-run_workflow","(workflow_name)","<p>Runs a workflow with a given name.\n<p>Displays a spinner indicating workflow execution and simulates completion. …\n"],["run_workflow","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-run_workflow","()","<p>Runs the defined workflow.\n<p>This method initiates the workflow execution, managing the lifecycle of tasks …\n"],["save_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-save_model","()","<p>Saves the topic model to the specified path.\n<p>@return [void]\n"],["save_state","WorkflowAgent","WorkflowAgent.html#method-i-save_state","()","<p>Saves the agent’s state to Redis.\n<p>@return [void]\n"],["segment_array","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-segment_array","()","<p>Segments an array of text.\n<p>@return [Array] An array of segments.\n"],["segment_string","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-segment_string","(txt)","<p>Segments a single string.\n<p>@param txt [String] The text to be segmented.\n<p>@return [Array] An array of segments. …\n"],["select_workflow","Flowbots::Workflows","Flowbots/Workflows.html#method-i-select_workflow","(workflows)","<p>Prompts the user to select a workflow from the list of available workflows.\n<p>@param workflows [Array&lt;Array( …\n"],["setup_redis","Flowbots","Flowbots.html#method-c-setup_redis","()","<p>Sets up the Redis connection for Ohm.\n<p>@return [void]\n@raise [Ohm::Error] If there is an error connecting ...\n"],["setup_workflow","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-setup_workflow","()",""],["shutdown","Flowbots","Flowbots.html#method-c-shutdown","()","<p>Shuts down the Flowbots application.\n<p>@return [void]\n"],["splat_sort","API","API.html#method-i-splat_sort","(splat_vals)","<p>Sorts splat values from the request URL and organizes them into a hash.\n<p>@param splat_vals [Array] The …\n"],["start","UI","UI.html#method-c-start","()","<p>Starts the main UI loop.\n<p>Displays the main menu and handles user interactions.\n<p>@return [void]\n"],["start_workflow","UI","UI.html#method-c-start_workflow","()","<p>Starts the workflow selection process.\n<p>Displays a menu of available workflows and handles user selection. …\n"],["stop_running_workflows","Flowbots","Flowbots.html#method-c-stop_running_workflows","()","<p>Stops any running workflows.\n<p>@return [void]\n"],["store_FileObject_id","FileLoaderTask","FileLoaderTask.html#method-i-store_FileObject_id","(id)","<p>Stores the FileObject ID in Redis.\n<p>@param id [Integer] The ID of the FileObject.\n<p>@return [void]\n"],["store_analysis_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-store_analysis_result","(textfile, result)","<p>Stores the analysis result in the Textfile.\n<p>@param textfile [Textfile] The Textfile object.\n@param result ...\n"],["store_episodic_memory","Agent","Agent.html#method-i-store_episodic_memory","(content)","<p>Store an episodic memory for the agent.\n<p>@param content [String] The content of the episodic memory.\n<p>@return …\n"],["store_file_data","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-store_file_data","(file_path, extracted_text)","<p>Stores the file data in the database.\n<p>@param file_path [String] The path to the file.\n@param extracted_text ...\n"],["store_preprocessed_data","PreprocessTextFileTask","PreprocessTextFileTask.html#method-i-store_preprocessed_data","(content, metadata)","<p>Stores the preprocessed content and metadata in the text file object.\n<p>@param content [String] The preprocessed …\n"],["store_result","TextTaggerTask","TextTaggerTask.html#method-i-store_result","(file_object, result, main_topics, speech_acts, transitivity)","<p>Stores the tagging results in the FileObject.\n<p>@param file_object [FileObject] The FileObject to store …\n"],["store_segments","TextSegmentTask","TextSegmentTask.html#method-i-store_segments","(textfile, segments)","<p>Stores the given segments in the given FileObject.\n<p>@param textfile [FileObject] The FileObject to store …\n"],["store_textfile_id","LoadTextFilesTask","LoadTextFilesTask.html#method-i-store_textfile_id","(id)","<p>Stores the Textfile ID in Redis.\n<p>@param id [Integer] The ID of the Textfile.\n<p>@return [void]\n"],["store_topic_result","TopicModelingTask","TopicModelingTask.html#method-i-store_topic_result","(textfile, result)","<p>Stores the topic modeling results in the given FileObject.\n<p>Extracts unique words from the topic results, …\n"],["tokenize_array","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-tokenize_array","()","<p>Tokenizes an array of strings.\n<p>@return [Array] An array of tokens.\n"],["tokenize_string","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-tokenize_string","(str)","<p>Tokenizes a single string.\n<p>@param str [String] The string to be tokenized.\n<p>@return [Array] An array of …\n"],["train_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-train_model","(documents, iterations=100)","<p>Trains a topic model using the provided documents.\n<p>@param documents [Array] An array of documents to train …\n"],["train_topic_model","Flowbots::CLI","Flowbots/CLI.html#method-i-train_topic_model","(folder)","<p>Trains a topic model using text files in the specified folder.\n<p>@param folder [String] The path to the …\n"],["train_topic_model","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-train_topic_model","()","<p>Trains the topic model using the filtered segments from the processed files.\n<p>Retrieves the filtered segments …\n"],["train_topic_model","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-train_topic_model","()",""],["update_file_object","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-update_file_object","(cleaned_segments)","<p>Updates the FileObject with the given cleaned segments.\n<p>@param cleaned_segments [Array&lt;Array&lt;String&gt;&gt;] …\n"],["update_segment_with_nlp_data","NlpAnalysisTask","NlpAnalysisTask.html#method-i-update_segment_with_nlp_data","(segment, processed_tokens, lemma_counts)","<p>Updates a segment with NLP data.\n<p>Extracts relevant NLP information from the processed tokens and updates …\n"],["update_semantic_memory","Agent","Agent.html#method-i-update_semantic_memory","(content)","<p>Update the agent’s semantic memory.\n<p>@param content [String] The content of the semantic memory.\n<p>@return …\n"],["update_state","WorkflowAgent","WorkflowAgent.html#method-i-update_state","(response)","<p>Updates the agent’s state with the latest response.\n<p>@param response [String] The agent’s response. …\n"],["upsert_document","FlowiseApiClient","FlowiseApiClient.html#method-i-upsert_document","(chatflow_id, file_path, local_ai_config={})","<p>Sends a document upsert request to the Flowise API.\n<p>@param chatflow_id [String] The ID of the chatflow …\n"],["version","Flowbots::CLI","Flowbots/CLI.html#method-i-version","()","<p>Displays the Flowbots version and Ruby environment information.\n<p>@return [void]\n"],["view_logs","UI","UI.html#method-c-view_logs","()","<p>Views the application logs.\n<p>Attempts to read the log file and display it in a scrollable box.\nHandles ...\n"],["workflows","Flowbots::CLI","Flowbots/CLI.html#method-i-workflows","()","<p>Lists available workflows, allows the user to select one, and runs it.\n<p>@return [void]\n"],["write_markdown_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-write_markdown_report","(report, exception_details)","<p>Writes the exception report to a markdown file.\n<p>@param report [String] The exception report.\n@param exception_details ...\n"],["write_markdown_report","LlmAnalysisTask","LlmAnalysisTask.html#method-i-write_markdown_report","(result)","<p>Writes the exception report to a markdown file.\n<p>@param report [String] The exception report.\n@param exception_details ...\n"],["yaml_front_matter","MarkdownYaml::Document0","MarkdownYaml/Document0.html#method-i-yaml_front_matter","()","<p>The YAML front matter section of the document.\n<p>@return [Treetop::Runtime::SyntaxNode] The YAML front matter …\n"],["LICENSE","","LICENSE.html","","<p>The MIT License (MIT)\n<p>Copyright © 2024 Robert Pannick\n<p>Permission is hereby granted, free of charge, to …\n"],["README","","README_md.html","","<p>Flowbots\n<p>Flowbots is an advanced text processing and analysis system that combines the power of ruby-nano-bots …\n"]]}}