var search_data = {"index":{"searchIndex":["api","accumulatefilteredsegmentstask","boxui","cursor","displayresultstask","fileloadertask","filtersegmentstask","flowbots","apierror","agenterror","cli","configurationerror","exceptionagent","exceptionhandler","fileloader","filenotfounderror","flowboterror","grammarprocessor","nlpprocessor","task","tasknotfounderror","textprocessingworkflow","textprocessor","textsegmentprocessor","texttaggerprocessor","texttokenizeprocessor","topicmodelprocessor","topicmodeltrainerworkflow","topicmodeltrainerworkflowtest","ui","workflowerror","workflows","flowiseapiclient","jongleur","workertask","llmanalysistask","loadFileObjectstask","logging","markdownyaml","document0","yamlfrontmatter0","yamlfrontmatter1","markdownyamlparser","monadicerror","nlpanalysistask","object","preprocessFileObjecttask","redisconnection","segment","sublayer","actions","runtestcommandaction","speechtotextaction","texttospeechaction","writefileaction","tty","markdown","converter","promptx","task","textsegmenttask","texttaggertask","texttokenizetask","FileObject","tokenizesegmentstask","topic","topicmodelingtask","traintopicmodeltask","uibox","word","workflowagent","workfloworchestrator","_nt_document()","_nt_markdown_content()","_nt_newline()","_nt_yaml_front_matter()","add_agent()","add_segments()","add_topics()","add_topics()","add_words()","add_words_to_segment()","after_delete()","after_save()","analyze_transitivity()","call()","call()","call()","call()","classify_file()","clean_segments()","clean_segments_for_modeling()","clean_segments_for_modeling()","cleanup()","comparison_box()","configure_logger_for()","convert_p()","create_doc()","create_new_model()","create_scrollable_box()","current_batch()","define_workflow()","display_boxes()","display_filtered_segments()","display_results()","display_workflows()","ensure_model_exists()","eval_result_box()","exception()","exception()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","execute()","exit_on_failure?()","extract_main_topics()","extract_markdown_content()","extract_metadata()","extract_relevant_files()","extract_text()","extract_workflow_description()","extract_yaml_front_matter()","fallback_exception_report()","filter_segment_words()","filter_segment_words()","filter_segments()","find_or_create_by_path()","flush_redis_cache()","flush_redis_cache()","format_analysis()","format_exception_report()","format_file_info()","format_nlp_result()","format_output()","generate_analysis_prompt()","generate_exception_prompt()","get_object_attributes()","get_object_bucket()","get_object_by_name()","get_object_collections()","get_object_indexed_attributes()","get_object_references()","get_objects()","get_objects_by_collection()","get_objects_by_query()","get_objects_by_reference()","get_objects_by_regex()","get_workflows()","handle_exception()","handle_response()","header()","identify_speech_acts()","in_container?()","infer_topics()","info()","info_box()","latest()","list_and_select()","load_engtagger()","load_existing_model()","load_file_structure()","load_grammar()","load_model()","load_or_create_model()","load_state()","load_tasks()","load_workflows()","log_exception()","log_level()","logger()","logger_for()","main()","markdown_content()","multi_column_box()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","new()","newline1()","newline2()","normalize_text()","notify_exception()","parse()","parse_pdf()","pos()","predict()","print_boxes()","print_navigation_info()","process()","process()","process()","process()","process()","process()","process_batch()","process_batch()","process_exception()","process_files()","process_files()","process_text()","prompt()","prompt_for_file()","prompt_for_folder()","prompt_for_folder()","readline()","response()","retrieve_current_FileObject()","retrieve_current_FileObject()","retrieve_current_FileObject()","retrieve_current_FileObject()","retrieve_file_metadata()","retrieve_filtered_words()","retrieve_input_text()","retrieve_nlp_result()","retrieve_preprocessed_content()","retrieve_segment_texts()","retrieve_segments()","retrieve_word_texts()","retrieve_word_texts()","retrieve_words()","retrieve_words()","root()","run()","run()","run()","run()","run_workflow()","save_model()","save_state()","say()","segment_array()","segment_string()","select_workflow()","setup_workflow()","setup_workflow()","setup_workflow()","shutdown()","side_by_side_boxes()","splat_sort()","stop_running_workflows()","store_analysis_result()","store_file_data()","store_input_file_path()","store_preprocessed_data()","store_result()","store_segments()","store_topic_result()","tokenize_array()","tokenize_string()","train_model()","train_topic_model()","train_topic_model()","train_topic_model()","update_state()","upsert_document()","version()","workflows()","write_markdown_report()","yaml_front_matter()","license","readme"],"longSearchIndex":["api","accumulatefilteredsegmentstask","boxui","cursor","displayresultstask","fileloadertask","filtersegmentstask","flowbots","flowbots::apierror","flowbots::agenterror","flowbots::cli","flowbots::configurationerror","flowbots::exceptionagent","flowbots::exceptionhandler","flowbots::fileloader","flowbots::filenotfounderror","flowbots::flowboterror","flowbots::grammarprocessor","flowbots::nlpprocessor","flowbots::task","flowbots::tasknotfounderror","flowbots::textprocessingworkflow","flowbots::textprocessor","flowbots::textsegmentprocessor","flowbots::texttaggerprocessor","flowbots::texttokenizeprocessor","flowbots::topicmodelprocessor","flowbots::topicmodeltrainerworkflow","flowbots::topicmodeltrainerworkflowtest","flowbots::ui","flowbots::workflowerror","flowbots::workflows","flowiseapiclient","jongleur","jongleur::workertask","llmanalysistask","loadFileObjectstask","logging","markdownyaml","markdownyaml::document0","markdownyaml::yamlfrontmatter0","markdownyaml::yamlfrontmatter1","markdownyamlparser","monadicerror","nlpanalysistask","object","preprocessFileObjecttask","redisconnection","segment","sublayer","sublayer::actions","sublayer::actions::runtestcommandaction","sublayer::actions::speechtotextaction","sublayer::actions::texttospeechaction","sublayer::actions::writefileaction","tty","tty::markdown","tty::markdown::converter","tty::promptx","task","textsegmenttask","texttaggertask","texttokenizetask","FileObject","tokenizesegmentstask","topic","topicmodelingtask","traintopicmodeltask","uibox","word","workflowagent","workfloworchestrator","markdownyaml#_nt_document()","markdownyaml#_nt_markdown_content()","markdownyaml#_nt_newline()","markdownyaml#_nt_yaml_front_matter()","workfloworchestrator#add_agent()","FileObject#add_segments()","segment#add_topics()","FileObject#add_topics()","segment#add_words()","nlpanalysistask#add_words_to_segment()","FileObject#after_delete()","FileObject#after_save()","flowbots::texttaggerprocessor#analyze_transitivity()","sublayer::actions::runtestcommandaction#call()","sublayer::actions::speechtotextaction#call()","sublayer::actions::texttospeechaction#call()","sublayer::actions::writefileaction#call()","flowbots::fileloader#classify_file()","accumulatefilteredsegmentstask#clean_segments()","flowbots::topicmodeltrainerworkflow#clean_segments_for_modeling()","flowbots::topicmodeltrainerworkflowtest#clean_segments_for_modeling()","workfloworchestrator#cleanup()","uibox::comparison_box()","logging::configure_logger_for()","tty::markdown::converter#convert_p()","flowbots::nlpprocessor#create_doc()","flowbots::topicmodelprocessor#create_new_model()","boxui::create_scrollable_box()","FileObject::current_batch()","workfloworchestrator#define_workflow()","boxui::display_boxes()","filtersegmentstask#display_filtered_segments()","displayresultstask#display_results()","flowbots::workflows#display_workflows()","flowbots::topicmodelprocessor#ensure_model_exists()","uibox::eval_result_box()","flowbots::ui#exception()","uibox::exception()","accumulatefilteredsegmentstask#execute()","displayresultstask#execute()","fileloadertask#execute()","filtersegmentstask#execute()","flowbots::task#execute()","llmanalysistask#execute()","loadFileObjectstask#execute()","nlpanalysistask#execute()","preprocessFileObjecttask#execute()","textsegmenttask#execute()","texttaggertask#execute()","texttokenizetask#execute()","tokenizesegmentstask#execute()","topicmodelingtask#execute()","traintopicmodeltask#execute()","flowbots::cli::exit_on_failure?()","flowbots::texttaggerprocessor#extract_main_topics()","flowbots::grammarprocessor#extract_markdown_content()","preprocessFileObjecttask#extract_metadata()","flowbots::exceptionagent#extract_relevant_files()","flowbots::fileloader#extract_text()","flowbots::workflows#extract_workflow_description()","flowbots::grammarprocessor#extract_yaml_front_matter()","flowbots::exceptionagent#fallback_exception_report()","filtersegmentstask#filter_segment_words()","topicmodelingtask#filter_segment_words()","filtersegmentstask#filter_segments()","FileObject::find_or_create_by_path()","flowbots::topicmodeltrainerworkflow#flush_redis_cache()","flowbots::topicmodeltrainerworkflowtest#flush_redis_cache()","displayresultstask#format_analysis()","flowbots::exceptionagent#format_exception_report()","displayresultstask#format_file_info()","llmanalysistask#format_nlp_result()","object#format_output()","llmanalysistask#generate_analysis_prompt()","flowbots::exceptionagent#generate_exception_prompt()","object#get_object_attributes()","object#get_object_bucket()","object#get_object_by_name()","object#get_object_collections()","object#get_object_indexed_attributes()","object#get_object_references()","object#get_objects()","object#get_objects_by_collection()","object#get_objects_by_query()","object#get_objects_by_reference()","object#get_objects_by_regex()","flowbots::workflows#get_workflows()","flowbots::exceptionhandler::handle_exception()","flowiseapiclient#handle_response()","flowbots::ui#header()","flowbots::texttaggerprocessor#identify_speech_acts()","object#in_container?()","flowbots::topicmodelprocessor#infer_topics()","flowbots::ui#info()","uibox::info_box()","FileObject::latest()","flowbots::workflows#list_and_select()","flowbots::texttaggerprocessor#load_engtagger()","flowbots::topicmodelprocessor#load_existing_model()","flowbots::exceptionagent#load_file_structure()","flowbots::grammarprocessor#load_grammar()","flowbots::nlpprocessor#load_model()","flowbots::topicmodelprocessor#load_or_create_model()","workflowagent#load_state()","flowbots::task::load_tasks()","flowbots::workflows::load_workflows()","flowbots::exceptionhandler::log_exception()","logging::log_level()","logging#logger()","logging::logger_for()","object#main()","markdownyaml::document0#markdown_content()","uibox::multi_column_box()","flowbots::exceptionagent::new()","flowbots::fileloader::new()","flowbots::flowboterror::new()","flowbots::grammarprocessor::new()","flowbots::nlpprocessor::new()","flowbots::task::new()","flowbots::textprocessingworkflow::new()","flowbots::textprocessor::new()","flowbots::textsegmentprocessor::new()","flowbots::texttaggerprocessor::new()","flowbots::texttokenizeprocessor::new()","flowbots::topicmodelprocessor::new()","flowbots::topicmodeltrainerworkflow::new()","flowbots::topicmodeltrainerworkflowtest::new()","flowbots::workflows::new()","flowiseapiclient::new()","redisconnection::new()","sublayer::actions::runtestcommandaction::new()","sublayer::actions::speechtotextaction::new()","sublayer::actions::texttospeechaction::new()","sublayer::actions::writefileaction::new()","tty::promptx::new()","workflowagent::new()","workfloworchestrator::new()","markdownyaml::yamlfrontmatter1#newline1()","markdownyaml::yamlfrontmatter1#newline2()","preprocessFileObjecttask#normalize_text()","flowbots::exceptionhandler::notify_exception()","flowbots::grammarprocessor#parse()","flowbots::fileloader#parse_pdf()","cursor::pos()","flowiseapiclient#predict()","boxui::print_boxes()","boxui::print_navigation_info()","flowbots::nlpprocessor#process()","flowbots::textprocessor#process()","flowbots::textsegmentprocessor#process()","flowbots::texttaggerprocessor#process()","flowbots::texttokenizeprocessor#process()","workflowagent#process()","flowbots::topicmodeltrainerworkflow#process_batch()","flowbots::topicmodeltrainerworkflowtest#process_batch()","flowbots::exceptionagent#process_exception()","flowbots::topicmodeltrainerworkflow#process_files()","flowbots::topicmodeltrainerworkflowtest#process_files()","flowbots::cli#process_text()","flowbots::ui#prompt()","flowbots::textprocessingworkflow#prompt_for_file()","flowbots::topicmodeltrainerworkflow#prompt_for_folder()","flowbots::topicmodeltrainerworkflowtest#prompt_for_folder()","tty::promptx#readline()","flowbots::ui#response()","displayresultstask#retrieve_current_FileObject()","llmanalysistask#retrieve_current_FileObject()","preprocessFileObjecttask#retrieve_current_FileObject()","topicmodelingtask#retrieve_current_FileObject()","llmanalysistask#retrieve_file_metadata()","topicmodelingtask#retrieve_filtered_words()","texttaggertask#retrieve_input_text()","llmanalysistask#retrieve_nlp_result()","textsegmenttask#retrieve_preprocessed_content()","FileObject#retrieve_segment_texts()","FileObject#retrieve_segments()","segment#retrieve_word_texts()","FileObject#retrieve_word_texts()","segment#retrieve_words()","FileObject#retrieve_words()","markdownyaml#root()","flowbots::textprocessingworkflow#run()","flowbots::topicmodeltrainerworkflow#run()","flowbots::topicmodeltrainerworkflowtest#run()","flowbots::workflows#run()","workfloworchestrator#run_workflow()","flowbots::topicmodelprocessor#save_model()","workflowagent#save_state()","flowbots::ui#say()","flowbots::textsegmentprocessor#segment_array()","flowbots::textsegmentprocessor#segment_string()","flowbots::workflows#select_workflow()","flowbots::textprocessingworkflow#setup_workflow()","flowbots::topicmodeltrainerworkflow#setup_workflow()","flowbots::topicmodeltrainerworkflowtest#setup_workflow()","flowbots::shutdown()","boxui::side_by_side_boxes()","api#splat_sort()","flowbots::stop_running_workflows()","llmanalysistask#store_analysis_result()","flowbots::fileloader#store_file_data()","flowbots::textprocessingworkflow#store_input_file_path()","preprocessFileObjecttask#store_preprocessed_data()","texttaggertask#store_result()","textsegmenttask#store_segments()","topicmodelingtask#store_topic_result()","flowbots::texttokenizeprocessor#tokenize_array()","flowbots::texttokenizeprocessor#tokenize_string()","flowbots::topicmodelprocessor#train_model()","flowbots::cli#train_topic_model()","flowbots::topicmodeltrainerworkflow#train_topic_model()","flowbots::topicmodeltrainerworkflowtest#train_topic_model()","workflowagent#update_state()","flowiseapiclient#upsert_document()","flowbots::cli#version()","flowbots::cli#workflows()","flowbots::exceptionagent#write_markdown_report()","markdownyaml::document0#yaml_front_matter()","",""],"info":[["API","","API.html","","<p>… (Ohm model definitions from OhmModels.rb) …\n"],["AccumulateFilteredSegmentsTask","","AccumulateFilteredSegmentsTask.html","","<p>This task accumulates filtered segments from multiple batches.\n"],["BoxUI","","BoxUI.html","","<p>Add this to your ui.rb file or create a new file called box_ui.rb\n"],["Cursor","","Cursor.html","",""],["DisplayResultsTask","","DisplayResultsTask.html","","<p>This task displays the results of the text processing workflow.\n"],["FileLoaderTask","","FileLoaderTask.html","","<p>This task loads a text file and stores its ID in Redis.\n"],["FilterSegmentsTask","","FilterSegmentsTask.html","","<p>This task filters segments based on their word tags.\n"],["Flowbots","","Flowbots.html","",""],["Flowbots::APIError","","Flowbots/APIError.html","",""],["Flowbots::AgentError","","Flowbots/AgentError.html","",""],["Flowbots::CLI","","Flowbots/CLI.html","","<p>This class provides a command-line interface (CLI) for interacting with the Flowbots application.\n"],["Flowbots::ConfigurationError","","Flowbots/ConfigurationError.html","",""],["Flowbots::ExceptionAgent","","Flowbots/ExceptionAgent.html","","<p>This class handles exceptions in the Flowbots application.\n"],["Flowbots::ExceptionHandler","","Flowbots/ExceptionHandler.html","","<p>This class handles exceptions in the Flowbots application.\n"],["Flowbots::FileLoader","","Flowbots/FileLoader.html","","<p>This class handles loading and processing text files.\n"],["Flowbots::FileNotFoundError","","Flowbots/FileNotFoundError.html","","<p>Custom error class for workflow file not found.\n"],["Flowbots::FlowbotError","","Flowbots/FlowbotError.html","",""],["Flowbots::GrammarProcessor","","Flowbots/GrammarProcessor.html","","<p>This class handles parsing text using a specified grammar.\n"],["Flowbots::NLPProcessor","","Flowbots/NLPProcessor.html","","<p>This class provides functionality for performing natural language processing (NLP) analysis on text. …\n"],["Flowbots::Task","","Flowbots/Task.html","","<p>This module encapsulates tasks used in Flowbots workflows.\n"],["Flowbots::TaskNotFoundError","","Flowbots/TaskNotFoundError.html","","<p>Custom error class for task not found.\n"],["Flowbots::TextProcessingWorkflow","","Flowbots/TextProcessingWorkflow.html","","<p>This class represents a workflow for processing text using topic modeling.\n"],["Flowbots::TextProcessor","","Flowbots/TextProcessor.html","","<p>This class provides a base class for text processors in the Flowbots application.\n"],["Flowbots::TextSegmentProcessor","","Flowbots/TextSegmentProcessor.html","","<p>This class provides functionality for segmenting text into smaller units.\n"],["Flowbots::TextTaggerProcessor","","Flowbots/TextTaggerProcessor.html","","<p>This class provides functionality for tagging text using the EngTagger library.\n"],["Flowbots::TextTokenizeProcessor","","Flowbots/TextTokenizeProcessor.html","","<p>This class provides functionality for tokenizing text.\n"],["Flowbots::TopicModelProcessor","","Flowbots/TopicModelProcessor.html","","<p>This class provides functionality for processing text using a topic model.\n"],["Flowbots::TopicModelTrainerWorkflow","","Flowbots/TopicModelTrainerWorkflow.html","",""],["Flowbots::TopicModelTrainerWorkflowtest","","Flowbots/TopicModelTrainerWorkflowtest.html","",""],["Flowbots::UI","","Flowbots/UI.html","",""],["Flowbots::WorkflowError","","Flowbots/WorkflowError.html","",""],["Flowbots::Workflows","","Flowbots/Workflows.html","","<p>This class manages workflows in the Flowbots application.\n"],["FlowiseApiClient","","FlowiseApiClient.html","","<p>This class provides an interface for interacting with the Flowise API.\n"],["Jongleur","","Jongleur.html","",""],["Jongleur::WorkerTask","","Jongleur/WorkerTask.html","","<p>Jongleur::WorkerTask is a class that defines a task to be executed by Jongleur.\n"],["LlmAnalysisTask","","LlmAnalysisTask.html","","<p>This task performs LLM analysis on a text file using a pre-trained model.\n"],["LoadFileObjectsTask","","LoadFileObjectsTask.html","","<p>This task loads a text file and stores its ID in Redis.\n"],["Logging","","Logging.html","",""],["MarkdownYaml","","MarkdownYaml.html","","<p>Autogenerated from a Treetop grammar. Edits may be lost.\n"],["MarkdownYaml::Document0","","MarkdownYaml/Document0.html","","<p>The Document node represents the entire document structure.\nIt contains the YAML front matter and the ...\n"],["MarkdownYaml::YamlFrontMatter0","","MarkdownYaml/YamlFrontMatter0.html","","<p>The YamlFrontMatter node represents the YAML front matter section.\n"],["MarkdownYaml::YamlFrontMatter1","","MarkdownYaml/YamlFrontMatter1.html","","<p>The YamlFrontMatter node represents the YAML front matter section.\n"],["MarkdownYamlParser","","MarkdownYamlParser.html","","<p>The MarkdownYamlParser class is responsible for parsing the Markdown YAML grammar.\n"],["MonadicError","","MonadicError.html","",""],["NlpAnalysisTask","","NlpAnalysisTask.html","","<p>This task performs natural language processing (NLP) analysis on the segments of a text file.\n"],["Object","","Object.html","",""],["PreprocessFileObjectTask","","PreprocessFileObjectTask.html","","<p>This task preprocesses a text file, extracting metadata and content.\n"],["RedisConnection","","RedisConnection.html","","<p>Define a class to manage Redis connection\n"],["Segment","","Segment.html","",""],["Sublayer","","Sublayer.html","","<p>blueprints.sublayer.com/blueprints/70562717-70c5-4406-a792-358d169f9f0b\n"],["Sublayer::Actions","","Sublayer/Actions.html","",""],["Sublayer::Actions::RunTestCommandAction","","Sublayer/Actions/RunTestCommandAction.html","",""],["Sublayer::Actions::SpeechToTextAction","","Sublayer/Actions/SpeechToTextAction.html","",""],["Sublayer::Actions::TextToSpeechAction","","Sublayer/Actions/TextToSpeechAction.html","",""],["Sublayer::Actions::WriteFileAction","","Sublayer/Actions/WriteFileAction.html","",""],["TTY","","TTY.html","",""],["TTY::Markdown","","TTY/Markdown.html","",""],["TTY::Markdown::Converter","","TTY/Markdown/Converter.html","","<p>Converts a Kramdown::Document tree to a terminal friendly output\n"],["TTY::PromptX","","TTY/PromptX.html","",""],["Task","","Task.html","",""],["TextSegmentTask","","TextSegmentTask.html","","<p>This task segments the text content of a FileObject into smaller units.\n"],["TextTaggerTask","","TextTaggerTask.html","","<p>This task performs text tagging using a pre-trained model.\n"],["TextTokenizeTask","","TextTokenizeTask.html","","<p>This task tokenizes the segments of a text file.\n"],["FileObject","","FileObject.html","",""],["TokenizeSegmentsTask","","TokenizeSegmentsTask.html","","<p>This task tokenizes the segments of a text file.\n"],["Topic","","Topic.html","",""],["TopicModelingTask","","TopicModelingTask.html","","<p>This task performs topic modeling on a text file using a pre-trained model.\n"],["TrainTopicModelTask","","TrainTopicModelTask.html","","<p>This task trains a topic model using filtered segments from multiple batches.\n"],["UIBox","","UIBox.html","",""],["Word","","Word.html","",""],["WorkflowAgent","","WorkflowAgent.html","","<p>This class represents an agent in a workflow.\nClass representing an individual agent within a workflow ...\n"],["WorkflowOrchestrator","","WorkflowOrchestrator.html","","<p>This class orchestrates the execution of workflows in the Flowbots application.\n"],["_nt_document","MarkdownYaml","MarkdownYaml.html#method-i-_nt_document","()","<p>Parses the document node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed document node.\n"],["_nt_markdown_content","MarkdownYaml","MarkdownYaml.html#method-i-_nt_markdown_content","()","<p>Parses the Markdown content node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed Markdown content node. …\n"],["_nt_newline","MarkdownYaml","MarkdownYaml.html#method-i-_nt_newline","()","<p>Parses the newline node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed newline node.\n"],["_nt_yaml_front_matter","MarkdownYaml","MarkdownYaml.html#method-i-_nt_yaml_front_matter","()","<p>Parses the YAML front matter node.\n<p>@return [Treetop::Runtime::SyntaxNode] The parsed YAML front matter …\n"],["add_agent","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-add_agent","(role, cartridge_file, author: \"@b08x\")","<p>Adds an agent to the orchestrator.\n<p>@param role [String] The role of the agent.\n@param cartridge_file [String] ...\n"],["add_segments","FileObject","FileObject.html#method-i-add_segments","(new_segments)","<p>Adds new segments to the FileObject object.\n<p>@param new_segments [Array] An array of new segment texts.\n<p>@return …\n"],["add_topics","Segment","Segment.html#method-i-add_topics","(new_topics)","<p>Adds new topics to the Segment object.\n<p>@param new_topics [Array] An array of new topic names.\n<p>@return [void] …\n"],["add_topics","FileObject","FileObject.html#method-i-add_topics","(new_topics)","<p>Adds new topics to the FileObject object.\n<p>@param new_topics [Array] An array of new topic names.\n<p>@return …\n"],["add_words","Segment","Segment.html#method-i-add_words","(new_words)","<p>Adds new words to the Segment object.\n<p>@param new_words [Array] An array of new word data.\n<p>@return [void] …\n"],["add_words_to_segment","NlpAnalysisTask","NlpAnalysisTask.html#method-i-add_words_to_segment","(segment, processed_tokens)","<p>Adds the processed words to the segment.\n<p>@param segment [Segment] The Segment object.\n@param processed_tokens ...\n"],["after_delete","FileObject","FileObject.html#method-i-after_delete","()","<p>Callback method executed after deleting the FileObject object.\n<p>@return [void]\n"],["after_save","FileObject","FileObject.html#method-i-after_save","()","<p>Callback method executed after saving the FileObject object.\n<p>@return [void]\n"],["analyze_transitivity","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-analyze_transitivity","(text)","<p>Analyzes the transitivity of sentences in the given text.\n<p>@param text [String] The text to analyze.\n<p>@return …\n"],["call","Sublayer::Actions::RunTestCommandAction","Sublayer/Actions/RunTestCommandAction.html#method-i-call","()",""],["call","Sublayer::Actions::SpeechToTextAction","Sublayer/Actions/SpeechToTextAction.html#method-i-call","()",""],["call","Sublayer::Actions::TextToSpeechAction","Sublayer/Actions/TextToSpeechAction.html#method-i-call","()",""],["call","Sublayer::Actions::WriteFileAction","Sublayer/Actions/WriteFileAction.html#method-i-call","()","<p>Writes the contents to the file in binary mode\n@return [void]\n"],["classify_file","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-classify_file","(file_path)","<p>Classifies the file type based on its MIME type.\n<p>@param file_path [String] The path to the file.\n<p>@return …\n"],["clean_segments","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-clean_segments","(segments)","<p>Cleans the filtered segments by removing empty segments, segments with specific keywords, and purely …\n"],["clean_segments_for_modeling","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-clean_segments_for_modeling","(segments)",""],["clean_segments_for_modeling","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-clean_segments_for_modeling","(segments)",""],["cleanup","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-cleanup","()","<p>Performs cleanup operations for the workflow.\n<p>@return [void]\n"],["comparison_box","UIBox","UIBox.html#method-c-comparison_box","(text1, text2, title1: \"Text 1\", title2: \"Text 2\")",""],["configure_logger_for","Logging","Logging.html#method-c-configure_logger_for","(_classname, _methodname)","<p>Configures a logger for the specified class and method.\n<p>@param &lt;em&gt;classname [String] The name of …\n"],["convert_p","TTY::Markdown::Converter","TTY/Markdown/Converter.html#method-i-convert_p","(ell, opts)",""],["create_doc","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-create_doc","(segment)","<p>Creates a Spacy::Doc object from the given segment’s tokens.\n<p>@param segment [Segment] The Segment …\n"],["create_new_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-create_new_model","()","<p>Creates a new topic model with the specified parameters.\n<p>@return [void]\n"],["create_scrollable_box","BoxUI","BoxUI.html#method-c-create_scrollable_box","(text, width, height, title)",""],["current_batch","FileObject","FileObject.html#method-c-current_batch","()","<p>Retrieves FileObject objects for the current batch.\n<p>@return [Array] An array of FileObject objects for the …\n"],["define_workflow","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-define_workflow","(workflow_definition)","<p>Defines a workflow using the given definition.\n<p>@param workflow_definition [Hash] The workflow definition. …\n"],["display_boxes","BoxUI","BoxUI.html#method-c-display_boxes","(box1, box2, box_height)",""],["display_filtered_segments","FilterSegmentsTask","FilterSegmentsTask.html#method-i-display_filtered_segments","(filtered_segments)","<p>Displays the filtered segments to the user.\n<p>@param filtered_segments [Array] An array of filtered segments. …\n"],["display_results","DisplayResultsTask","DisplayResultsTask.html#method-i-display_results","(FileObject, analysis_result)","<p>Displays the results of the text processing workflow.\n<p>@param FileObject [FileObject] The FileObject object. …\n"],["display_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-i-display_workflows","(workflows)","<p>Displays a list of available workflows in a table format.\n<p>@param workflows [Array] An array of workflow …\n"],["ensure_model_exists","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-ensure_model_exists","()","<p>Ensures that the topic model exists, loading or creating it if necessary.\n<p>@return [void]\n"],["eval_result_box","UIBox","UIBox.html#method-c-eval_result_box","(result, title: \"Evaluation Result\")",""],["exception","Flowbots::UI","Flowbots/UI.html#method-i-exception","(text)",""],["exception","UIBox","UIBox.html#method-c-exception","(message)",""],["execute","AccumulateFilteredSegmentsTask","AccumulateFilteredSegmentsTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","DisplayResultsTask","DisplayResultsTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","FileLoaderTask","FileLoaderTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","FilterSegmentsTask","FilterSegmentsTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","Flowbots::Task","Flowbots/Task.html#method-i-execute","()","<p>Executes the task.\n<p>This method must be implemented in subclasses.\n<p>@return [void]\n@raise [NotImplementedError] ...\n"],["execute","LlmAnalysisTask","LlmAnalysisTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","LoadFileObjectsTask","LoadFileObjectsTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","NlpAnalysisTask","NlpAnalysisTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","PreprocessFileObjectTask","PreprocessFileObjectTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TextSegmentTask","TextSegmentTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TextTaggerTask","TextTaggerTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TextTokenizeTask","TextTokenizeTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TokenizeSegmentsTask","TokenizeSegmentsTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TopicModelingTask","TopicModelingTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["execute","TrainTopicModelTask","TrainTopicModelTask.html#method-i-execute","()","<p>Executes the task.\n<p>@return [void]\n"],["exit_on_failure?","Flowbots::CLI","Flowbots/CLI.html#method-c-exit_on_failure-3F","()","<p>Defines whether the CLI should exit with a non-zero status code when an error occurs.\n<p>@return [Boolean] …\n"],["extract_main_topics","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-extract_main_topics","(text, limit=5)","<p>Extracts the main topics from the given text.\n<p>@param text [String] The text to extract topics from.\n@param ...\n"],["extract_markdown_content","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-extract_markdown_content","(parse_result)","<p>Extracts the Markdown content from the parse result.\n<p>@param parse_result [Treetop::Runtime::SyntaxNode] …\n"],["extract_metadata","PreprocessFileObjectTask","PreprocessFileObjectTask.html#method-i-extract_metadata","(yaml_front_matter)","<p>Extracts metadata from the YAML front matter.\n<p>@param yaml_front_matter [String] The YAML front matter …\n"],["extract_relevant_files","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-extract_relevant_files","(exception)","<p>Extracts relevant files from the exception backtrace.\n<p>@param exception [Exception] The exception object. …\n"],["extract_text","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-extract_text","(file_type, file_path)","<p>Extracts the text content from a file based on its type.\n<p>@param file_type [Symbol] The file type.\n@param ...\n"],["extract_workflow_description","Flowbots::Workflows","Flowbots/Workflows.html#method-i-extract_workflow_description","(file)","<p>Extracts the description of a workflow from its file.\n<p>@param file [String] The path to the workflow file. …\n"],["extract_yaml_front_matter","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-extract_yaml_front_matter","(parse_result)","<p>Extracts the YAML front matter from the parse result.\n<p>@param parse_result [Treetop::Runtime::SyntaxNode] …\n"],["fallback_exception_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-fallback_exception_report","(exception_details)","<p>Generates a fallback exception report if the agent fails to generate a report.\n<p>@param exception_details …\n"],["filter_segment_words","FilterSegmentsTask","FilterSegmentsTask.html#method-i-filter_segment_words","(segment)","<p>Filters words from a segment based on their tags.\n<p>@param segment [Segment] The Segment object.\n<p>@return …\n"],["filter_segment_words","TopicModelingTask","TopicModelingTask.html#method-i-filter_segment_words","(segment)","<p>Filters words from a segment based on their tags.\n<p>@param segment [Segment] The Segment object.\n<p>@return …\n"],["filter_segments","FilterSegmentsTask","FilterSegmentsTask.html#method-i-filter_segments","(text_file)","<p>Filters segments based on their word tags.\n<p>@param text_file [FileObject] The FileObject object.\n<p>@return [Array] …\n"],["find_or_create_by_path","FileObject","FileObject.html#method-c-find_or_create_by_path","(file_path, attributes={})","<p>Finds or creates a FileObject object based on the provided file path and attributes.\n<p>@param file_path [String] …\n"],["flush_redis_cache","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-flush_redis_cache","()",""],["flush_redis_cache","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-flush_redis_cache","()",""],["format_analysis","DisplayResultsTask","DisplayResultsTask.html#method-i-format_analysis","(analysis_result)","<p>Formats the analysis result for display.\n<p>@param analysis_result [String] The analysis result.\n<p>@return [String] …\n"],["format_exception_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-format_exception_report","(agent_response, exception_details)","<p>Formats the exception report based on the agent’s response.\n<p>@param agent_response [String] The response …\n"],["format_file_info","DisplayResultsTask","DisplayResultsTask.html#method-i-format_file_info","(FileObject)","<p>Formats the file information for display.\n<p>@param FileObject [FileObject] The FileObject object.\n<p>@return [String] …\n"],["format_nlp_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-format_nlp_result","(nlp_result)","<p>Formats the NLP results for display in the prompt.\n<p>@param nlp_result [Array] The NLP results for the segments …\n"],["format_output","Object","Object.html#method-i-format_output","(objects)",""],["generate_analysis_prompt","LlmAnalysisTask","LlmAnalysisTask.html#method-i-generate_analysis_prompt","(FileObject, content, metadata, nlp_result)","<p>Generates a prompt for the LLM analysis agent.\n<p>@param FileObject [FileObject] The FileObject object.\n@param ...\n"],["generate_exception_prompt","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-generate_exception_prompt","(exception_details)","<p>Generates a prompt for the exception handler agent.\n<p>@param exception_details [Hash] A hash containing …\n"],["get_object_attributes","Object","Object.html#method-i-get_object_attributes","(object_bucket)",""],["get_object_bucket","Object","Object.html#method-i-get_object_bucket","(object_bucket)",""],["get_object_by_name","Object","Object.html#method-i-get_object_by_name","(object_bucket, object_name)",""],["get_object_collections","Object","Object.html#method-i-get_object_collections","(object_bucket)",""],["get_object_indexed_attributes","Object","Object.html#method-i-get_object_indexed_attributes","(object_bucket)",""],["get_object_references","Object","Object.html#method-i-get_object_references","(object_bucket)",""],["get_objects","Object","Object.html#method-i-get_objects","(object_bucket, object_name, query=nil)",""],["get_objects_by_collection","Object","Object.html#method-i-get_objects_by_collection","(object_bucket, collection_name)",""],["get_objects_by_query","Object","Object.html#method-i-get_objects_by_query","(object_bucket, query)",""],["get_objects_by_reference","Object","Object.html#method-i-get_objects_by_reference","(object_bucket, reference_name, reference_value)",""],["get_objects_by_regex","Object","Object.html#method-i-get_objects_by_regex","(object_bucket, regex)",""],["get_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-i-get_workflows","()","<p>Retrieves a list of available workflows.\n<p>@return [Array] An array of workflow names and descriptions. …\n"],["handle_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-handle_exception","(classname=nil, exception)","<p>Handles an exception by generating a report and notifying relevant parties.\n<p>@param classname [String] …\n"],["handle_response","FlowiseApiClient","FlowiseApiClient.html#method-i-handle_response","(response)","<p>Handles the response from the Flowise API.\n<p>@param response [Faraday::Response] The response from the  …\n"],["header","Flowbots::UI","Flowbots/UI.html#method-i-header","()",""],["identify_speech_acts","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-identify_speech_acts","(text)","<p>Identifies the speech acts in the given text.\n<p>@param text [String] The text to analyze.\n<p>@return [Array] …\n"],["in_container?","Object","Object.html#method-i-in_container-3F","()","<p>from Monadic-Chat, MonadicApp class:\nreturn true if we are inside a docker container\n"],["infer_topics","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-infer_topics","(document)","<p>Infers the topics for a given document.\n<p>@param document [String] The document to infer topics for.\n<p>@return …\n"],["info","Flowbots::UI","Flowbots/UI.html#method-i-info","(text)",""],["info_box","UIBox","UIBox.html#method-c-info_box","(message, title: \"Info\")",""],["latest","FileObject","FileObject.html#method-c-latest","(limit=nil)","<p>Retrieves the latest FileObject object from Redis.\n<p>@param limit [Integer] The maximum number of FileObject …\n"],["list_and_select","Flowbots::Workflows","Flowbots/Workflows.html#method-i-list_and_select","()","<p>Lists available workflows and allows the user to select one.\n<p>@return [String, nil] The name of the selected …\n"],["load_engtagger","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-load_engtagger","()","<p>Loads the EngTagger library.\n<p>@return [void]\n"],["load_existing_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-load_existing_model","()","<p>Loads an existing topic model from the specified path.\n<p>@return [void]\n"],["load_file_structure","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-load_file_structure","()","<p>Loads the file structure from the flowbots.json file.\n<p>@return [Hash] The file structure.\n"],["load_grammar","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-load_grammar","()","<p>Loads the grammar file and creates a parser instance.\n<p>@return [void]\n"],["load_model","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-load_model","()","<p>Loads the NLP model from the specified environment variable.\n<p>@return [void]\n"],["load_or_create_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-load_or_create_model","()","<p>Loads an existing topic model or creates a new one if it doesn’t exist.\n<p>@return [void]\n"],["load_state","WorkflowAgent","WorkflowAgent.html#method-i-load_state","()","<p>Loads the agent’s state from Redis.\n<p>@return [void]\n"],["load_tasks","Flowbots::Task","Flowbots/Task.html#method-c-load_tasks","()","<p>Loads all task files from the TASK_DIR directory.\n<p>@return [void]\n"],["load_workflows","Flowbots::Workflows","Flowbots/Workflows.html#method-c-load_workflows","()","<p>Loads all workflow files from the WORKFLOW_DIR directory.\n<p>@return [void]\n"],["log_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-log_exception","(exception)","<p>Logs an exception to the application’s logger.\n<p>@param exception [Exception] The exception object. …\n"],["log_level","Logging","Logging.html#method-c-log_level","()","<p>Returns the default log level.\n<p>@return [Integer] The log level.\n"],["logger","Logging","Logging.html#method-i-logger","()","<p>Returns the logger for the current class and method.\n<p>@return [Logger] The logger object.\n"],["logger_for","Logging","Logging.html#method-c-logger_for","(classname, methodname)","<p>Returns the logger for the specified class and method.\n<p>@param classname [String] The name of the class. …\n"],["main","Object","Object.html#method-i-main","()",""],["markdown_content","MarkdownYaml::Document0","MarkdownYaml/Document0.html#method-i-markdown_content","()","<p>The Markdown content section of the document.\n<p>@return [Treetop::Runtime::SyntaxNode] The Markdown content …\n"],["multi_column_box","UIBox","UIBox.html#method-c-multi_column_box","(data, titles)",""],["new","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-c-new","()","<p>Initializes a new instance of the ExceptionAgent class.\n<p>@return [void]\n"],["new","Flowbots::FileLoader","Flowbots/FileLoader.html#method-c-new","(file_path)","<p>Initializes a new FileLoader instance.\n<p>@param file_path [String] The path to the file to be loaded.\n<p>@return …\n"],["new","Flowbots::FlowbotError","Flowbots/FlowbotError.html#method-c-new","(message, error_code, details={})",""],["new","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-c-new","(grammar_name)","<p>Initializes a new GrammarProcessor instance.\n<p>@param grammar_name [String] The name of the grammar to use …\n"],["new","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-c-new","()","<p>Initializes a new NLPProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::Task","Flowbots/Task.html#method-c-new","(options={})","<p>Initializes a new Task instance.\n<p>@param options [Hash] A hash of options for the task.\n<p>@return [void]\n"],["new","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-c-new","(input_file_path=nil)","<p>Initializes a new TextProcessingWorkflow instance.\n<p>@param input_file_path [String] The path to the input …\n"],["new","Flowbots::TextProcessor","Flowbots/TextProcessor.html#method-c-new","()","<p>Initializes a new TextProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-c-new","()","<p>Initializes a new TextSegmentProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-c-new","()","<p>Initializes a new TextTaggerProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-c-new","()","<p>Initializes a new TextTokenizeProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-c-new","()","<p>Initializes a new TopicModelProcessor instance.\n<p>@return [void]\n"],["new","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-c-new","(input_folder_path=nil)",""],["new","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-c-new","(input_folder_path=nil)",""],["new","Flowbots::Workflows","Flowbots/Workflows.html#method-c-new","()","<p>Initializes a new Workflows instance.\n<p>@return [void]\n"],["new","FlowiseApiClient","FlowiseApiClient.html#method-c-new","(base_url)","<p>Initializes a new FlowiseApiClient instance.\n<p>@param base_url [String] The base URL of the Flowise API …\n"],["new","RedisConnection","RedisConnection.html#method-c-new","()",""],["new","Sublayer::Actions::RunTestCommandAction","Sublayer/Actions/RunTestCommandAction.html#method-c-new","(test_command:)",""],["new","Sublayer::Actions::SpeechToTextAction","Sublayer/Actions/SpeechToTextAction.html#method-c-new","(audio_data)",""],["new","Sublayer::Actions::TextToSpeechAction","Sublayer/Actions/TextToSpeechAction.html#method-c-new","(text)",""],["new","Sublayer::Actions::WriteFileAction","Sublayer/Actions/WriteFileAction.html#method-c-new","(file_contents:, file_path:)","<p>Initializes the action with the contents to write and the target file path\n@param [String] file_contents ...\n"],["new","TTY::PromptX","TTY/PromptX.html#method-c-new","(active_color:, prefix:, history: true)",""],["new","WorkflowAgent","WorkflowAgent.html#method-c-new","(role, cartridge_file)","<p>Initializes a new WorkflowAgent instance.\n<p>@param role [String] The role of the agent.\n@param cartridge_file ...\n"],["new","WorkflowOrchestrator","WorkflowOrchestrator.html#method-c-new","()","<p>Initializes a new WorkflowOrchestrator instance.\n<p>@return [void]\n"],["newline1","MarkdownYaml::YamlFrontMatter1","MarkdownYaml/YamlFrontMatter1.html#method-i-newline1","()","<p>The first newline character after the “—” delimiter.\n<p>@return [Treetop::Runtime::SyntaxNode] …\n"],["newline2","MarkdownYaml::YamlFrontMatter1","MarkdownYaml/YamlFrontMatter1.html#method-i-newline2","()","<p>The second newline character after the “—” delimiter.\n<p>@return [Treetop::Runtime::SyntaxNode] …\n"],["normalize_text","PreprocessFileObjectTask","PreprocessFileObjectTask.html#method-i-normalize_text","(text)","<p>Normalizes the given text by converting it to lowercase and removing non-alphanumeric characters.\n<p>@param …\n"],["notify_exception","Flowbots::ExceptionHandler","Flowbots/ExceptionHandler.html#method-c-notify_exception","(report)","<p>Notifies relevant parties about an exception.\n<p>@param report [String] The formatted exception report.\n<p>@return …\n"],["parse","Flowbots::GrammarProcessor","Flowbots/GrammarProcessor.html#method-i-parse","(text)","<p>Parses the given text using the specified grammar.\n<p>@param text [String] The text to parse.\n<p>@return [Hash, …\n"],["parse_pdf","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-parse_pdf","(file_path)","<p>Parses a PDF file and extracts its text content.\n<p>@param file_path [String] The path to the PDF file.\n<p>@return …\n"],["pos","Cursor","Cursor.html#method-c-pos","()",""],["predict","FlowiseApiClient","FlowiseApiClient.html#method-i-predict","(chatflow_id, options={})","<p>Sends a prediction request to the Flowise API.\n<p>@param chatflow_id [String] The ID of the chatflow to use …\n"],["print_boxes","BoxUI","BoxUI.html#method-c-print_boxes","(box1, box2, box_height)",""],["print_navigation_info","BoxUI","BoxUI.html#method-c-print_navigation_info","(box1, box2)",""],["process","Flowbots::NLPProcessor","Flowbots/NLPProcessor.html#method-i-process","(segment, options={})","<p>Processes the given segment using the loaded NLP model and returns a hash of processed tokens.\n<p>@param …\n"],["process","Flowbots::TextProcessor","Flowbots/TextProcessor.html#method-i-process","(text)","<p>Processes the given text.\n<p>This method must be implemented in subclasses.\n<p>@param text [String] The text …\n"],["process","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-process","(text, opts={})","<p>Segments the given text using the specified options.\n<p>@param text [String, Array] The text to be segmented. …\n"],["process","Flowbots::TextTaggerProcessor","Flowbots/TextTaggerProcessor.html#method-i-process","(text, options={})","<p>Processes the given text using the EngTagger library and returns a hash of tagged results.\n<p>@param text …\n"],["process","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-process","(text, opts={})","<p>Tokenizes the given text using the specified options.\n<p>@param text [String, Array] The text to be tokenized. …\n"],["process","WorkflowAgent","WorkflowAgent.html#method-i-process","(input)","<p>Processes the given input using the agent’s cartridge.\n<p>@param input [String] The input to process. …\n"],["process_batch","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-process_batch","(batch_files)",""],["process_batch","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-process_batch","(batch_files)",""],["process_exception","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-process_exception","(classname, exception)","<p>Processes an exception and generates a report.\n<p>@param classname [String] The name of the class where the …\n"],["process_files","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-process_files","()",""],["process_files","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-process_files","()",""],["process_text","Flowbots::CLI","Flowbots/CLI.html#method-i-process_text","(file)","<p>Processes a text file using the text processing workflow.\n<p>@param file [String] The path to the text file. …\n"],["prompt","Flowbots::UI","Flowbots/UI.html#method-i-prompt","()",""],["prompt_for_file","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-prompt_for_file","()","<p>Prompts the user for the input file path.\n<p>@return [String] The path to the input file.\n"],["prompt_for_folder","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-prompt_for_folder","()",""],["prompt_for_folder","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-prompt_for_folder","()",""],["readline","TTY::PromptX","TTY/PromptX.html#method-i-readline","(text = \"\")",""],["response","Flowbots::UI","Flowbots/UI.html#method-i-response","(response)",""],["retrieve_current_FileObject","DisplayResultsTask","DisplayResultsTask.html#method-i-retrieve_current_FileObject","()","<p>Retrieves the current FileObject object from Redis.\n<p>@return [FileObject] The FileObject object representing …\n"],["retrieve_current_FileObject","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_current_FileObject","()","<p>Retrieves the current FileObject object from Redis.\n<p>@return [FileObject] The FileObject object representing …\n"],["retrieve_current_FileObject","PreprocessFileObjectTask","PreprocessFileObjectTask.html#method-i-retrieve_current_FileObject","()","<p>Retrieves the current FileObject object from Redis.\n<p>@return [FileObject] The FileObject object representing …\n"],["retrieve_current_FileObject","TopicModelingTask","TopicModelingTask.html#method-i-retrieve_current_FileObject","()","<p>Retrieves the current FileObject object from Redis.\n<p>@return [FileObject] The FileObject object representing …\n"],["retrieve_file_metadata","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_file_metadata","()","<p>Retrieves the file metadata from Redis.\n<p>@return [Hash] The file metadata.\n"],["retrieve_filtered_words","TopicModelingTask","TopicModelingTask.html#method-i-retrieve_filtered_words","(text_file)","<p>Retrieves filtered words from the FileObject.\n<p>@param text_file [FileObject] The FileObject object.\n<p>@return [Array] …\n"],["retrieve_input_text","TextTaggerTask","TextTaggerTask.html#method-i-retrieve_input_text","()","<p>Retrieves the FileObject object from Redis.\n<p>@return [FileObject] The FileObject object.\n"],["retrieve_nlp_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-retrieve_nlp_result","(FileObject)","<p>Retrieves the NLP results for the segments of the FileObject.\n<p>@param FileObject [FileObject] The FileObject object. …\n"],["retrieve_preprocessed_content","TextSegmentTask","TextSegmentTask.html#method-i-retrieve_preprocessed_content","()","<p>Retrieves the preprocessed content from Redis.\n<p>@return [String] The preprocessed content.\n"],["retrieve_segment_texts","FileObject","FileObject.html#method-i-retrieve_segment_texts","()","<p>Retrieves the text content of all segments associated with the FileObject object.\n<p>@return [Array] An array …\n"],["retrieve_segments","FileObject","FileObject.html#method-i-retrieve_segments","()","<p>Retrieves all segments associated with the FileObject object.\n<p>@return [Array] An array of Segment objects. …\n"],["retrieve_word_texts","Segment","Segment.html#method-i-retrieve_word_texts","()","<p>Retrieves the text content of all words associated with the Segment object.\n<p>@return [Array] An array of …\n"],["retrieve_word_texts","FileObject","FileObject.html#method-i-retrieve_word_texts","()","<p>Retrieves the text content of all words associated with the FileObject object.\n<p>@return [Array] An array …\n"],["retrieve_words","Segment","Segment.html#method-i-retrieve_words","()","<p>Retrieves all words associated with the Segment object.\n<p>@return [Array] An array of Word objects.\n"],["retrieve_words","FileObject","FileObject.html#method-i-retrieve_words","()","<p>Retrieves all words associated with the FileObject object.\n<p>@return [Array] An array of Word objects.\n"],["root","MarkdownYaml","MarkdownYaml.html#method-i-root","()","<p>The root node of the grammar.\n<p>@return [Treetop::Runtime::SyntaxNode] The root node of the grammar.\n"],["run","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-run","()","<p>Runs the text processing workflow.\n<p>@return [void]\n"],["run","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-run","()",""],["run","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-run","()",""],["run","Flowbots::Workflows","Flowbots/Workflows.html#method-i-run","(workflow_name)","<p>Runs the specified workflow.\n<p>@param workflow_name [String] The name of the workflow to run.\n<p>@return [void] …\n"],["run_workflow","WorkflowOrchestrator","WorkflowOrchestrator.html#method-i-run_workflow","()","<p>Runs the defined workflow.\n<p>@return [void]\n"],["save_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-save_model","()","<p>Saves the topic model to the specified path.\n<p>@return [void]\n"],["save_state","WorkflowAgent","WorkflowAgent.html#method-i-save_state","()","<p>Saves the agent’s state to Redis.\n<p>@return [void]\n"],["say","Flowbots::UI","Flowbots/UI.html#method-i-say","(type, statement)",""],["segment_array","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-segment_array","()","<p>Segments an array of text.\n<p>@return [Array] An array of segments.\n"],["segment_string","Flowbots::TextSegmentProcessor","Flowbots/TextSegmentProcessor.html#method-i-segment_string","(txt)","<p>Segments a single string.\n<p>@param txt [String] The text to be segmented.\n<p>@return [Array] An array of segments. …\n"],["select_workflow","Flowbots::Workflows","Flowbots/Workflows.html#method-i-select_workflow","(workflows)","<p>Prompts the user to select a workflow from the list.\n<p>@param workflows [Array] An array of workflow names …\n"],["setup_workflow","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-setup_workflow","()","<p>Sets up the workflow graph.\n<p>@return [void]\n"],["setup_workflow","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-setup_workflow","()",""],["setup_workflow","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-setup_workflow","()",""],["shutdown","Flowbots","Flowbots.html#method-c-shutdown","()",""],["side_by_side_boxes","BoxUI","BoxUI.html#method-c-side_by_side_boxes","(text1, text2, title1: \"Box 1\", title2: \"Box 2\")",""],["splat_sort","API","API.html#method-i-splat_sort","(splat_vals)","<p>… (Add routes for other object buckets and their attributes) …\n"],["stop_running_workflows","Flowbots","Flowbots.html#method-c-stop_running_workflows","()",""],["store_analysis_result","LlmAnalysisTask","LlmAnalysisTask.html#method-i-store_analysis_result","(FileObject, result)","<p>Stores the analysis result in the FileObject.\n<p>@param FileObject [FileObject] The FileObject object.\n@param result ...\n"],["store_file_data","Flowbots::FileLoader","Flowbots/FileLoader.html#method-i-store_file_data","(file_path, extracted_text)","<p>Stores the file data in the database.\n<p>@param file_path [String] The path to the file.\n@param extracted_text ...\n"],["store_input_file_path","Flowbots::TextProcessingWorkflow","Flowbots/TextProcessingWorkflow.html#method-i-store_input_file_path","()","<p>Stores the input file path in Redis.\n<p>@return [void]\n"],["store_preprocessed_data","PreprocessFileObjectTask","PreprocessFileObjectTask.html#method-i-store_preprocessed_data","(content, metadata)","<p>Stores the preprocessed content and metadata in the database.\n<p>@param content [String] The preprocessed …\n"],["store_result","TextTaggerTask","TextTaggerTask.html#method-i-store_result","(FileObject, result)","<p>Stores the result in the FileObject.\n<p>@param FileObject [FileObject] The FileObject object.\n@param result [Hash] ...\n"],["store_segments","TextSegmentTask","TextSegmentTask.html#method-i-store_segments","(text_file, segments)","<p>Stores the segmented content in the FileObject.\n<p>@param text_file [FileObject] The FileObject object.\n@param ...\n"],["store_topic_result","TopicModelingTask","TopicModelingTask.html#method-i-store_topic_result","(text_file, result)","<p>Stores the topic modeling results in the FileObject.\n<p>@param text_file [FileObject] The FileObject object.\n@param ...\n"],["tokenize_array","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-tokenize_array","()","<p>Tokenizes an array of strings.\n<p>@return [Array] An array of tokens.\n"],["tokenize_string","Flowbots::TextTokenizeProcessor","Flowbots/TextTokenizeProcessor.html#method-i-tokenize_string","(str)","<p>Tokenizes a single string.\n<p>@param str [String] The string to be tokenized.\n<p>@return [Array] An array of …\n"],["train_model","Flowbots::TopicModelProcessor","Flowbots/TopicModelProcessor.html#method-i-train_model","(documents, iterations=100)","<p>Trains a topic model using the provided documents.\n<p>@param documents [Array] An array of documents to train …\n"],["train_topic_model","Flowbots::CLI","Flowbots/CLI.html#method-i-train_topic_model","(folder)","<p>Trains a topic model using text files in the specified folder.\n<p>@param folder [String] The path to the …\n"],["train_topic_model","Flowbots::TopicModelTrainerWorkflow","Flowbots/TopicModelTrainerWorkflow.html#method-i-train_topic_model","()",""],["train_topic_model","Flowbots::TopicModelTrainerWorkflowtest","Flowbots/TopicModelTrainerWorkflowtest.html#method-i-train_topic_model","()",""],["update_state","WorkflowAgent","WorkflowAgent.html#method-i-update_state","(response)","<p>Updates the agent’s state with the latest response.\n<p>@param response [String] The agent’s response. …\n"],["upsert_document","FlowiseApiClient","FlowiseApiClient.html#method-i-upsert_document","(chatflow_id, file_path, local_ai_config={})","<p>Sends a document upsert request to the Flowise API.\n<p>@param chatflow_id [String] The ID of the chatflow …\n"],["version","Flowbots::CLI","Flowbots/CLI.html#method-i-version","()","<p>Displays the Flowbots version and Ruby environment information.\n<p>@return [void]\n"],["workflows","Flowbots::CLI","Flowbots/CLI.html#method-i-workflows","()","<p>Lists available workflows, allows the user to select one, and runs it.\n<p>@return [void]\n"],["write_markdown_report","Flowbots::ExceptionAgent","Flowbots/ExceptionAgent.html#method-i-write_markdown_report","(report, exception_details)","<p>Writes the exception report to a markdown file.\n<p>@param report [String] The exception report.\n@param exception_details ...\n"],["yaml_front_matter","MarkdownYaml::Document0","MarkdownYaml/Document0.html#method-i-yaml_front_matter","()","<p>The YAML front matter section of the document.\n<p>@return [Treetop::Runtime::SyntaxNode] The YAML front matter …\n"],["LICENSE","","LICENSE.html","","<p>The MIT License (MIT)\n<p>Copyright © 2024 Robert Pannick\n<p>Permission is hereby granted, free of charge, to …\n"],["README","","README_md.html","","<p>Flowbots: Prompt Compression and Evaluation Workflow\n<p>Flowbots is a Ruby-based workflow orchestration system …\n"]]}}